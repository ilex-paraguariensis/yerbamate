{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oalee/yerbamate/blob/main/deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "First we need to install python and mate\n",
        "\n"
      ],
      "metadata": {
        "id": "V-cEx0Py9kOe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALs5kCr_Y4_b"
      },
      "outputs": [],
      "source": [
        "!wget -O mini.sh https://repo.anaconda.com/miniconda/Miniconda3-py39_4.9.2-Linux-x86_64.sh\n",
        "!chmod +x mini.sh\n",
        "!bash ./mini.sh -b -f -p /usr/local\n",
        "!conda install -q -y jupyter\n",
        "!conda install -q -y google-colab -c conda-forge\n",
        "!python -m ipykernel install --name \"py39\" --use\n",
        "!pip install -U pip yerbamate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0n5ToYVS9aVf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we need to set up the drive for loading data and saving weights"
      ],
      "metadata": {
        "id": "Sm1vEJkg9a0W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhDAffrPmndR"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we need to inialize a new project"
      ],
      "metadata": {
        "id": "VzM_ybji9vNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if os.getcwd() != \"/content/drive/MyDrive/\":\n",
        "  os.chdir('/content/drive/MyDrive')\n",
        "!mate init deepnet\n",
        "%cd deepnet\n"
      ],
      "metadata": {
        "id": "Z5LOpfe5fYIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is where the magic happens, you can install experiments from any github mate project and train. Simply push your code on github, and use your link to train here 🤗"
      ],
      "metadata": {
        "id": "UzlYwEWh92Is"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxqjA34QY6fT"
      },
      "outputs": [],
      "source": [
        "!mate install oalee/big_transfer/experiments/bit -yo pip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Don't for get to set up the environment variables 😊 "
      ],
      "metadata": {
        "id": "IbkwfiQk-GoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"datadir\"] = \"./data\"\n",
        "os.environ[\"results\"] = \"./results\"\n",
        "os.environ[\"logdir\"] = \"./logs\"\n",
        "os.environ[\"weights_path\"] = \"./weights\""
      ],
      "metadata": {
        "id": "fOV9LVQxfXDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see what we have"
      ],
      "metadata": {
        "id": "aDXg07cH-PO8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ln2nr4buspM",
        "outputId": "99f71361-7709-496f-a81b-86a5115c3d81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"models\": [\n",
            "        \"bit_torch\"\n",
            "    ],\n",
            "    \"trainers\": [\n",
            "        \"bit_torch\"\n",
            "    ],\n",
            "    \"data\": [\n",
            "        \"bit\"\n",
            "    ],\n",
            "    \"experiments\": {\n",
            "        \"bit\": [\n",
            "            \"learn.py\"\n",
            "        ]\n",
            "    }\n",
            "}\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!mate list"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then Train 🌊"
      ],
      "metadata": {
        "id": "IYVdXtqb-bRt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dA5JTWAR0agt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e561b5a0-ce61-48de-de0c-a98224308fe9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Using a training set with 50000 images.\n",
            "Using a validation set with 10000 images.\n",
            "Loading model from ./weights/BiT-M-R50x1.npz\n",
            "Loaded model from ./weights/BiT-M-R50x1.npz\n",
            "2023-02-13 17:00:09,738 [INFO] train: Going to train on cuda:0\n",
            "2023-02-13 17:00:09,739 [INFO] train: Moving model onto all GPUs\n",
            "2023-02-13 17:00:13,208 [INFO] train: Model will be saved in 'bit/learn/trained_BiT-M-R50x1.pt'\n",
            "2023-02-13 17:00:13,208 [INFO] train: Fine-tuning from BiT\n",
            "2023-02-13 17:00:13,213 [INFO] train: Starting training!\n",
            "2023-02-13 17:00:15,540 [INFO] train: [step 0 (1/2)]: loss=2.302584887 (lr=0.0e+00 (val_top1=0.00%))\n",
            "2023-02-13 17:00:15,692 [INFO] train: [step 0 (2/2)]: loss=2.302584887 (lr=0.0e+00 (val_top1=0.00%))\n",
            "2023-02-13 17:00:15,887 [INFO] train: [step 1 (1/2)]: loss=2.302584887 (lr=2.0e-06 (val_top1=0.00%))\n",
            "2023-02-13 17:00:16,088 [INFO] train: [step 1 (2/2)]: loss=2.302584887 (lr=2.0e-06 (val_top1=0.00%))\n",
            "2023-02-13 17:00:16,295 [INFO] train: [step 2 (1/2)]: loss=2.302111626 (lr=4.0e-06 (val_top1=0.00%))\n",
            "2023-02-13 17:00:16,563 [INFO] train: [step 2 (2/2)]: loss=2.301892996 (lr=4.0e-06 (val_top1=0.00%))\n",
            "2023-02-13 17:00:16,840 [INFO] train: [step 3 (1/2)]: loss=2.300541878 (lr=6.0e-06 (val_top1=0.00%))\n",
            "2023-02-13 17:00:17,095 [INFO] train: [step 3 (2/2)]: loss=2.300707579 (lr=6.0e-06 (val_top1=0.00%))\n",
            "2023-02-13 17:00:17,367 [INFO] train: [step 4 (1/2)]: loss=2.300600052 (lr=8.0e-06 (val_top1=0.00%))\n",
            "2023-02-13 17:00:17,613 [INFO] train: [step 4 (2/2)]: loss=2.301679373 (lr=8.0e-06 (val_top1=0.00%))\n",
            "2023-02-13 17:00:17,819 [INFO] train: [step 5 (1/2)]: loss=2.292415142 (lr=1.0e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:18,031 [INFO] train: [step 5 (2/2)]: loss=2.294824839 (lr=1.0e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:18,255 [INFO] train: [step 6 (1/2)]: loss=2.286867380 (lr=1.2e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:18,457 [INFO] train: [step 6 (2/2)]: loss=2.286808014 (lr=1.2e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:18,699 [INFO] train: [step 7 (1/2)]: loss=2.276865244 (lr=1.4e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:18,907 [INFO] train: [step 7 (2/2)]: loss=2.279247046 (lr=1.4e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:19,103 [INFO] train: [step 8 (1/2)]: loss=2.265450716 (lr=1.6e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:19,296 [INFO] train: [step 8 (2/2)]: loss=2.275437355 (lr=1.6e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:19,509 [INFO] train: [step 9 (1/2)]: loss=2.253208876 (lr=1.8e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:19,719 [INFO] train: [step 9 (2/2)]: loss=2.245550632 (lr=1.8e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:19,932 [INFO] train: [step 10 (1/2)]: loss=2.238797665 (lr=2.0e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:20,137 [INFO] train: [step 10 (2/2)]: loss=2.236940622 (lr=2.0e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:20,348 [INFO] train: [step 11 (1/2)]: loss=2.226661205 (lr=2.2e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:20,558 [INFO] train: [step 11 (2/2)]: loss=2.216273308 (lr=2.2e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:20,776 [INFO] train: [step 12 (1/2)]: loss=2.182220936 (lr=2.4e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:20,978 [INFO] train: [step 12 (2/2)]: loss=2.204694271 (lr=2.4e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:21,185 [INFO] train: [step 13 (1/2)]: loss=2.235588551 (lr=2.6e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:21,395 [INFO] train: [step 13 (2/2)]: loss=2.245858192 (lr=2.6e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:21,606 [INFO] train: [step 14 (1/2)]: loss=2.164885998 (lr=2.8e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:21,817 [INFO] train: [step 14 (2/2)]: loss=2.147884369 (lr=2.8e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:22,031 [INFO] train: [step 15 (1/2)]: loss=2.120147228 (lr=3.0e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:22,237 [INFO] train: [step 15 (2/2)]: loss=2.116182089 (lr=3.0e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:22,446 [INFO] train: [step 16 (1/2)]: loss=2.095722914 (lr=3.2e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:22,654 [INFO] train: [step 16 (2/2)]: loss=2.075415611 (lr=3.2e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:22,868 [INFO] train: [step 17 (1/2)]: loss=2.045320511 (lr=3.4e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:23,076 [INFO] train: [step 17 (2/2)]: loss=2.046468735 (lr=3.4e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:23,285 [INFO] train: [step 18 (1/2)]: loss=2.159739971 (lr=3.6e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:23,495 [INFO] train: [step 18 (2/2)]: loss=2.169410229 (lr=3.6e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:23,709 [INFO] train: [step 19 (1/2)]: loss=1.961293697 (lr=3.8e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:23,913 [INFO] train: [step 19 (2/2)]: loss=1.981273532 (lr=3.8e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:24,124 [INFO] train: [step 20 (1/2)]: loss=1.947584629 (lr=4.0e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:24,338 [INFO] train: [step 20 (2/2)]: loss=1.924026012 (lr=4.0e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:24,549 [INFO] train: [step 21 (1/2)]: loss=1.917117596 (lr=4.2e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:24,760 [INFO] train: [step 21 (2/2)]: loss=1.856766105 (lr=4.2e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:24,974 [INFO] train: [step 22 (1/2)]: loss=1.836404443 (lr=4.4e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:25,182 [INFO] train: [step 22 (2/2)]: loss=1.825841665 (lr=4.4e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:25,391 [INFO] train: [step 23 (1/2)]: loss=1.743589759 (lr=4.6e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:25,596 [INFO] train: [step 23 (2/2)]: loss=1.745949864 (lr=4.6e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:25,808 [INFO] train: [step 24 (1/2)]: loss=1.722244740 (lr=4.8e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:26,015 [INFO] train: [step 24 (2/2)]: loss=1.726449370 (lr=4.8e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:26,228 [INFO] train: [step 25 (1/2)]: loss=1.598437428 (lr=5.0e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:26,439 [INFO] train: [step 25 (2/2)]: loss=1.686812878 (lr=5.0e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:26,649 [INFO] train: [step 26 (1/2)]: loss=1.607059002 (lr=5.2e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:26,858 [INFO] train: [step 26 (2/2)]: loss=1.613574624 (lr=5.2e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:27,069 [INFO] train: [step 27 (1/2)]: loss=1.599707961 (lr=5.4e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:27,277 [INFO] train: [step 27 (2/2)]: loss=1.586673141 (lr=5.4e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:27,492 [INFO] train: [step 28 (1/2)]: loss=1.499785423 (lr=5.6e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:27,699 [INFO] train: [step 28 (2/2)]: loss=1.543093801 (lr=5.6e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:27,914 [INFO] train: [step 29 (1/2)]: loss=1.400410295 (lr=5.8e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:28,122 [INFO] train: [step 29 (2/2)]: loss=1.389836311 (lr=5.8e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:28,334 [INFO] train: [step 30 (1/2)]: loss=1.388137817 (lr=6.0e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:28,545 [INFO] train: [step 30 (2/2)]: loss=1.519205451 (lr=6.0e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:28,762 [INFO] train: [step 31 (1/2)]: loss=1.760231256 (lr=6.2e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:28,973 [INFO] train: [step 31 (2/2)]: loss=1.849338293 (lr=6.2e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:29,189 [INFO] train: [step 32 (1/2)]: loss=1.331173897 (lr=6.4e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:29,400 [INFO] train: [step 32 (2/2)]: loss=1.390490294 (lr=6.4e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:29,632 [INFO] train: [step 33 (1/2)]: loss=1.299066305 (lr=6.6e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:29,844 [INFO] train: [step 33 (2/2)]: loss=1.349226117 (lr=6.6e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:30,048 [INFO] train: [step 34 (1/2)]: loss=1.150618553 (lr=6.8e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:30,263 [INFO] train: [step 34 (2/2)]: loss=1.229959846 (lr=6.8e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:30,481 [INFO] train: [step 35 (1/2)]: loss=1.166449666 (lr=7.0e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:30,695 [INFO] train: [step 35 (2/2)]: loss=1.174299836 (lr=7.0e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:30,911 [INFO] train: [step 36 (1/2)]: loss=1.029389501 (lr=7.2e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:31,122 [INFO] train: [step 36 (2/2)]: loss=1.193801045 (lr=7.2e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:31,333 [INFO] train: [step 37 (1/2)]: loss=2.017341614 (lr=7.4e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:31,548 [INFO] train: [step 37 (2/2)]: loss=1.957796097 (lr=7.4e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:31,768 [INFO] train: [step 38 (1/2)]: loss=0.991529047 (lr=7.6e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:31,979 [INFO] train: [step 38 (2/2)]: loss=1.016823530 (lr=7.6e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:32,194 [INFO] train: [step 39 (1/2)]: loss=1.049437761 (lr=7.8e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:32,405 [INFO] train: [step 39 (2/2)]: loss=0.970347106 (lr=7.8e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:32,624 [INFO] train: [step 40 (1/2)]: loss=0.971305251 (lr=8.0e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:32,848 [INFO] train: [step 40 (2/2)]: loss=0.992326379 (lr=8.0e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:33,074 [INFO] train: [step 41 (1/2)]: loss=1.120993972 (lr=8.2e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:33,289 [INFO] train: [step 41 (2/2)]: loss=1.167150617 (lr=8.2e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:33,509 [INFO] train: [step 42 (1/2)]: loss=0.849086940 (lr=8.4e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:33,721 [INFO] train: [step 42 (2/2)]: loss=0.953891158 (lr=8.4e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:33,958 [INFO] train: [step 43 (1/2)]: loss=0.904503584 (lr=8.6e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:34,163 [INFO] train: [step 43 (2/2)]: loss=0.962231755 (lr=8.6e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:34,374 [INFO] train: [step 44 (1/2)]: loss=0.866805494 (lr=8.8e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:34,595 [INFO] train: [step 44 (2/2)]: loss=0.701234102 (lr=8.8e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:34,803 [INFO] train: [step 45 (1/2)]: loss=0.850014746 (lr=9.0e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:35,037 [INFO] train: [step 45 (2/2)]: loss=0.895286918 (lr=9.0e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:35,237 [INFO] train: [step 46 (1/2)]: loss=0.891342163 (lr=9.2e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:35,462 [INFO] train: [step 46 (2/2)]: loss=1.000330687 (lr=9.2e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:35,691 [INFO] train: [step 47 (1/2)]: loss=0.853665829 (lr=9.4e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:35,900 [INFO] train: [step 47 (2/2)]: loss=0.883676469 (lr=9.4e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:36,119 [INFO] train: [step 48 (1/2)]: loss=0.592141747 (lr=9.6e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:36,328 [INFO] train: [step 48 (2/2)]: loss=0.675357521 (lr=9.6e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:36,554 [INFO] train: [step 49 (1/2)]: loss=1.038553476 (lr=9.8e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:36,768 [INFO] train: [step 49 (2/2)]: loss=0.969127357 (lr=9.8e-05 (val_top1=0.00%))\n",
            "2023-02-13 17:00:36,982 [INFO] train: [step 50 (1/2)]: loss=0.551488340 (lr=1.0e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:37,195 [INFO] train: [step 50 (2/2)]: loss=0.663743734 (lr=1.0e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:37,409 [INFO] train: [step 51 (1/2)]: loss=0.466142327 (lr=1.0e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:37,615 [INFO] train: [step 51 (2/2)]: loss=0.507417202 (lr=1.0e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:37,844 [INFO] train: [step 52 (1/2)]: loss=0.584875166 (lr=1.0e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:38,045 [INFO] train: [step 52 (2/2)]: loss=0.466115266 (lr=1.0e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:38,291 [INFO] train: [step 53 (1/2)]: loss=0.891870022 (lr=1.1e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:38,498 [INFO] train: [step 53 (2/2)]: loss=0.791375935 (lr=1.1e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:38,719 [INFO] train: [step 54 (1/2)]: loss=1.584317207 (lr=1.1e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:38,918 [INFO] train: [step 54 (2/2)]: loss=1.589046001 (lr=1.1e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:39,133 [INFO] train: [step 55 (1/2)]: loss=0.512515008 (lr=1.1e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:39,379 [INFO] train: [step 55 (2/2)]: loss=0.480542570 (lr=1.1e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:39,576 [INFO] train: [step 56 (1/2)]: loss=0.366999328 (lr=1.1e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:39,802 [INFO] train: [step 56 (2/2)]: loss=0.440568000 (lr=1.1e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:40,026 [INFO] train: [step 57 (1/2)]: loss=1.557952166 (lr=1.1e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:40,230 [INFO] train: [step 57 (2/2)]: loss=1.407699823 (lr=1.1e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:40,444 [INFO] train: [step 58 (1/2)]: loss=0.420689344 (lr=1.2e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:40,665 [INFO] train: [step 58 (2/2)]: loss=0.448219359 (lr=1.2e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:40,889 [INFO] train: [step 59 (1/2)]: loss=0.432537735 (lr=1.2e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:41,102 [INFO] train: [step 59 (2/2)]: loss=0.435494930 (lr=1.2e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:41,343 [INFO] train: [step 60 (1/2)]: loss=0.451438725 (lr=1.2e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:41,541 [INFO] train: [step 60 (2/2)]: loss=0.402725428 (lr=1.2e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:41,767 [INFO] train: [step 61 (1/2)]: loss=1.084864616 (lr=1.2e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:41,979 [INFO] train: [step 61 (2/2)]: loss=1.159189701 (lr=1.2e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:42,211 [INFO] train: [step 62 (1/2)]: loss=0.499258965 (lr=1.2e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:42,422 [INFO] train: [step 62 (2/2)]: loss=0.401603431 (lr=1.2e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:42,639 [INFO] train: [step 63 (1/2)]: loss=0.492397040 (lr=1.3e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:42,851 [INFO] train: [step 63 (2/2)]: loss=0.411677420 (lr=1.3e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:43,083 [INFO] train: [step 64 (1/2)]: loss=0.447764814 (lr=1.3e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:43,300 [INFO] train: [step 64 (2/2)]: loss=0.400288910 (lr=1.3e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:43,521 [INFO] train: [step 65 (1/2)]: loss=1.855399728 (lr=1.3e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:43,727 [INFO] train: [step 65 (2/2)]: loss=1.891221046 (lr=1.3e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:43,945 [INFO] train: [step 66 (1/2)]: loss=0.452218711 (lr=1.3e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:44,160 [INFO] train: [step 66 (2/2)]: loss=0.478931338 (lr=1.3e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:44,378 [INFO] train: [step 67 (1/2)]: loss=0.555717051 (lr=1.3e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:44,591 [INFO] train: [step 67 (2/2)]: loss=0.487228602 (lr=1.3e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:44,806 [INFO] train: [step 68 (1/2)]: loss=0.632605195 (lr=1.4e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:45,019 [INFO] train: [step 68 (2/2)]: loss=0.620088220 (lr=1.4e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:45,238 [INFO] train: [step 69 (1/2)]: loss=0.458485574 (lr=1.4e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:45,452 [INFO] train: [step 69 (2/2)]: loss=0.318068594 (lr=1.4e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:45,669 [INFO] train: [step 70 (1/2)]: loss=0.365921944 (lr=1.4e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:45,882 [INFO] train: [step 70 (2/2)]: loss=0.347472250 (lr=1.4e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:46,097 [INFO] train: [step 71 (1/2)]: loss=0.438183933 (lr=1.4e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:46,309 [INFO] train: [step 71 (2/2)]: loss=0.418351978 (lr=1.4e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:46,528 [INFO] train: [step 72 (1/2)]: loss=0.318707645 (lr=1.4e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:46,740 [INFO] train: [step 72 (2/2)]: loss=0.365027457 (lr=1.4e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:46,958 [INFO] train: [step 73 (1/2)]: loss=0.383674264 (lr=1.5e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:47,171 [INFO] train: [step 73 (2/2)]: loss=0.320364118 (lr=1.5e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:47,388 [INFO] train: [step 74 (1/2)]: loss=0.420043230 (lr=1.5e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:47,605 [INFO] train: [step 74 (2/2)]: loss=0.360352725 (lr=1.5e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:47,820 [INFO] train: [step 75 (1/2)]: loss=0.893919945 (lr=1.5e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:48,040 [INFO] train: [step 75 (2/2)]: loss=0.928882658 (lr=1.5e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:48,256 [INFO] train: [step 76 (1/2)]: loss=0.312978268 (lr=1.5e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:48,472 [INFO] train: [step 76 (2/2)]: loss=0.372194499 (lr=1.5e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:48,690 [INFO] train: [step 77 (1/2)]: loss=0.283852726 (lr=1.5e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:48,906 [INFO] train: [step 77 (2/2)]: loss=0.218111098 (lr=1.5e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:49,121 [INFO] train: [step 78 (1/2)]: loss=1.865193844 (lr=1.6e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:49,335 [INFO] train: [step 78 (2/2)]: loss=1.763135076 (lr=1.6e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:49,554 [INFO] train: [step 79 (1/2)]: loss=0.438179731 (lr=1.6e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:49,767 [INFO] train: [step 79 (2/2)]: loss=0.197047099 (lr=1.6e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:49,984 [INFO] train: [step 80 (1/2)]: loss=1.498596907 (lr=1.6e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:50,203 [INFO] train: [step 80 (2/2)]: loss=1.509603262 (lr=1.6e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:50,420 [INFO] train: [step 81 (1/2)]: loss=0.345185220 (lr=1.6e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:50,645 [INFO] train: [step 81 (2/2)]: loss=0.279290676 (lr=1.6e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:50,854 [INFO] train: [step 82 (1/2)]: loss=0.315908402 (lr=1.6e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:51,067 [INFO] train: [step 82 (2/2)]: loss=0.191514105 (lr=1.6e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:51,312 [INFO] train: [step 83 (1/2)]: loss=0.519262671 (lr=1.7e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:51,500 [INFO] train: [step 83 (2/2)]: loss=0.197378159 (lr=1.7e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:51,722 [INFO] train: [step 84 (1/2)]: loss=0.250955969 (lr=1.7e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:51,948 [INFO] train: [step 84 (2/2)]: loss=0.274167389 (lr=1.7e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:52,152 [INFO] train: [step 85 (1/2)]: loss=0.334169090 (lr=1.7e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:52,367 [INFO] train: [step 85 (2/2)]: loss=0.297536045 (lr=1.7e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:52,586 [INFO] train: [step 86 (1/2)]: loss=0.341615200 (lr=1.7e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:52,802 [INFO] train: [step 86 (2/2)]: loss=0.305594832 (lr=1.7e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:53,020 [INFO] train: [step 87 (1/2)]: loss=0.209563330 (lr=1.7e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:53,240 [INFO] train: [step 87 (2/2)]: loss=0.249465778 (lr=1.7e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:53,455 [INFO] train: [step 88 (1/2)]: loss=0.334576428 (lr=1.8e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:53,671 [INFO] train: [step 88 (2/2)]: loss=0.269343138 (lr=1.8e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:53,895 [INFO] train: [step 89 (1/2)]: loss=0.887191415 (lr=1.8e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:54,113 [INFO] train: [step 89 (2/2)]: loss=0.877739847 (lr=1.8e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:54,340 [INFO] train: [step 90 (1/2)]: loss=0.317816913 (lr=1.8e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:54,562 [INFO] train: [step 90 (2/2)]: loss=0.253875464 (lr=1.8e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:54,780 [INFO] train: [step 91 (1/2)]: loss=0.594762087 (lr=1.8e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:55,003 [INFO] train: [step 91 (2/2)]: loss=0.663429976 (lr=1.8e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:55,228 [INFO] train: [step 92 (1/2)]: loss=1.862020135 (lr=1.8e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:55,440 [INFO] train: [step 92 (2/2)]: loss=1.865410924 (lr=1.8e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:55,663 [INFO] train: [step 93 (1/2)]: loss=1.483199358 (lr=1.9e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:55,873 [INFO] train: [step 93 (2/2)]: loss=1.289319754 (lr=1.9e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:56,101 [INFO] train: [step 94 (1/2)]: loss=0.635130167 (lr=1.9e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:56,317 [INFO] train: [step 94 (2/2)]: loss=0.593057275 (lr=1.9e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:56,538 [INFO] train: [step 95 (1/2)]: loss=0.348511755 (lr=1.9e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:56,758 [INFO] train: [step 95 (2/2)]: loss=0.396073133 (lr=1.9e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:56,981 [INFO] train: [step 96 (1/2)]: loss=0.296277255 (lr=1.9e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:57,197 [INFO] train: [step 96 (2/2)]: loss=0.280173808 (lr=1.9e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:57,423 [INFO] train: [step 97 (1/2)]: loss=0.330722094 (lr=1.9e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:57,648 [INFO] train: [step 97 (2/2)]: loss=0.383500278 (lr=1.9e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:57,879 [INFO] train: [step 98 (1/2)]: loss=0.351959080 (lr=2.0e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:58,086 [INFO] train: [step 98 (2/2)]: loss=0.280166984 (lr=2.0e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:58,314 [INFO] train: [step 99 (1/2)]: loss=0.370585591 (lr=2.0e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:58,538 [INFO] train: [step 99 (2/2)]: loss=0.429309219 (lr=2.0e-04 (val_top1=0.00%))\n",
            "2023-02-13 17:00:58,577 [INFO] train: Running validation...\n",
            "2023-02-13 17:00:58,886 [INFO] train: Validation@100 batch 0 loss 0.29932, top1 92.19%, \n",
            "2023-02-13 17:00:59,105 [INFO] train: Validation@100 batch 1 loss 0.17003, top1 98.44%, \n",
            "2023-02-13 17:00:59,193 [INFO] train: Validation@100 batch 2 loss 0.25076, top1 93.75%, \n",
            "2023-02-13 17:00:59,267 [INFO] train: Validation@100 batch 3 loss 0.29101, top1 93.75%, \n",
            "2023-02-13 17:00:59,351 [INFO] train: Validation@100 batch 4 loss 0.21530, top1 92.19%, \n",
            "2023-02-13 17:00:59,430 [INFO] train: Validation@100 batch 5 loss 0.20010, top1 92.19%, \n",
            "2023-02-13 17:00:59,511 [INFO] train: Validation@100 batch 6 loss 0.27160, top1 93.75%, \n",
            "2023-02-13 17:00:59,600 [INFO] train: Validation@100 batch 7 loss 0.22333, top1 93.75%, \n",
            "2023-02-13 17:00:59,711 [INFO] train: Validation@100 batch 8 loss 0.17069, top1 96.88%, \n",
            "2023-02-13 17:00:59,834 [INFO] train: Validation@100 batch 9 loss 0.25552, top1 95.31%, \n",
            "2023-02-13 17:00:59,912 [INFO] train: Validation@100 batch 10 loss 0.25771, top1 93.75%, \n",
            "2023-02-13 17:00:59,992 [INFO] train: Validation@100 batch 11 loss 0.31768, top1 84.38%, \n",
            "2023-02-13 17:01:00,090 [INFO] train: Validation@100 batch 12 loss 0.29006, top1 92.19%, \n",
            "2023-02-13 17:01:00,193 [INFO] train: Validation@100 batch 13 loss 0.26197, top1 93.75%, \n",
            "2023-02-13 17:01:00,316 [INFO] train: Validation@100 batch 14 loss 0.17845, top1 95.31%, \n",
            "2023-02-13 17:01:00,412 [INFO] train: Validation@100 batch 15 loss 0.10874, top1 98.44%, \n",
            "2023-02-13 17:01:00,497 [INFO] train: Validation@100 batch 16 loss 0.22372, top1 93.75%, \n",
            "2023-02-13 17:01:00,638 [INFO] train: Validation@100 batch 17 loss 0.22041, top1 93.75%, \n",
            "2023-02-13 17:01:00,716 [INFO] train: Validation@100 batch 18 loss 0.15666, top1 93.75%, \n",
            "2023-02-13 17:01:00,808 [INFO] train: Validation@100 batch 19 loss 0.21280, top1 95.31%, \n",
            "2023-02-13 17:01:00,885 [INFO] train: Validation@100 batch 20 loss 0.19099, top1 95.31%, \n",
            "2023-02-13 17:01:01,035 [INFO] train: Validation@100 batch 21 loss 0.25202, top1 90.62%, \n",
            "2023-02-13 17:01:01,118 [INFO] train: Validation@100 batch 22 loss 0.16249, top1 96.88%, \n",
            "2023-02-13 17:01:01,255 [INFO] train: Validation@100 batch 23 loss 0.22707, top1 93.75%, \n",
            "2023-02-13 17:01:01,331 [INFO] train: Validation@100 batch 24 loss 0.29738, top1 92.19%, \n",
            "2023-02-13 17:01:01,415 [INFO] train: Validation@100 batch 25 loss 0.30152, top1 90.62%, \n",
            "2023-02-13 17:01:01,494 [INFO] train: Validation@100 batch 26 loss 0.20375, top1 93.75%, \n",
            "2023-02-13 17:01:01,615 [INFO] train: Validation@100 batch 27 loss 0.33511, top1 89.06%, \n",
            "2023-02-13 17:01:01,688 [INFO] train: Validation@100 batch 28 loss 0.13658, top1 98.44%, \n",
            "2023-02-13 17:01:01,795 [INFO] train: Validation@100 batch 29 loss 0.25988, top1 92.19%, \n",
            "2023-02-13 17:01:01,868 [INFO] train: Validation@100 batch 30 loss 0.34988, top1 87.50%, \n",
            "2023-02-13 17:01:02,013 [INFO] train: Validation@100 batch 31 loss 0.29359, top1 90.62%, \n",
            "2023-02-13 17:01:02,101 [INFO] train: Validation@100 batch 32 loss 0.21575, top1 92.19%, \n",
            "2023-02-13 17:01:02,251 [INFO] train: Validation@100 batch 33 loss 0.27991, top1 95.31%, \n",
            "2023-02-13 17:01:02,328 [INFO] train: Validation@100 batch 34 loss 0.19523, top1 98.44%, \n",
            "2023-02-13 17:01:02,459 [INFO] train: Validation@100 batch 35 loss 0.24779, top1 92.19%, \n",
            "2023-02-13 17:01:02,541 [INFO] train: Validation@100 batch 36 loss 0.23766, top1 92.19%, \n",
            "2023-02-13 17:01:02,642 [INFO] train: Validation@100 batch 37 loss 0.33962, top1 95.31%, \n",
            "2023-02-13 17:01:02,735 [INFO] train: Validation@100 batch 38 loss 0.18318, top1 98.44%, \n",
            "2023-02-13 17:01:02,838 [INFO] train: Validation@100 batch 39 loss 0.35188, top1 85.94%, \n",
            "2023-02-13 17:01:02,915 [INFO] train: Validation@100 batch 40 loss 0.21399, top1 95.31%, \n",
            "2023-02-13 17:01:03,049 [INFO] train: Validation@100 batch 41 loss 0.18509, top1 98.44%, \n",
            "2023-02-13 17:01:03,136 [INFO] train: Validation@100 batch 42 loss 0.24041, top1 95.31%, \n",
            "2023-02-13 17:01:03,235 [INFO] train: Validation@100 batch 43 loss 0.25885, top1 90.62%, \n",
            "2023-02-13 17:01:03,387 [INFO] train: Validation@100 batch 44 loss 0.19188, top1 96.88%, \n",
            "2023-02-13 17:01:03,463 [INFO] train: Validation@100 batch 45 loss 0.21078, top1 93.75%, \n",
            "2023-02-13 17:01:03,538 [INFO] train: Validation@100 batch 46 loss 0.31259, top1 93.75%, \n",
            "2023-02-13 17:01:03,611 [INFO] train: Validation@100 batch 47 loss 0.23469, top1 93.75%, \n",
            "2023-02-13 17:01:03,763 [INFO] train: Validation@100 batch 48 loss 0.27003, top1 90.62%, \n",
            "2023-02-13 17:01:03,837 [INFO] train: Validation@100 batch 49 loss 0.32821, top1 90.62%, \n",
            "2023-02-13 17:01:03,963 [INFO] train: Validation@100 batch 50 loss 0.16938, top1 96.88%, \n",
            "2023-02-13 17:01:04,040 [INFO] train: Validation@100 batch 51 loss 0.20608, top1 92.19%, \n",
            "2023-02-13 17:01:04,159 [INFO] train: Validation@100 batch 52 loss 0.27218, top1 92.19%, \n",
            "2023-02-13 17:01:04,237 [INFO] train: Validation@100 batch 53 loss 0.32522, top1 92.19%, \n",
            "2023-02-13 17:01:04,375 [INFO] train: Validation@100 batch 54 loss 0.25536, top1 95.31%, \n",
            "2023-02-13 17:01:04,471 [INFO] train: Validation@100 batch 55 loss 0.22078, top1 95.31%, \n",
            "2023-02-13 17:01:04,559 [INFO] train: Validation@100 batch 56 loss 0.20376, top1 95.31%, \n",
            "2023-02-13 17:01:04,652 [INFO] train: Validation@100 batch 57 loss 0.26673, top1 89.06%, \n",
            "2023-02-13 17:01:04,745 [INFO] train: Validation@100 batch 58 loss 0.24089, top1 90.62%, \n",
            "2023-02-13 17:01:04,822 [INFO] train: Validation@100 batch 59 loss 0.31795, top1 87.50%, \n",
            "2023-02-13 17:01:04,951 [INFO] train: Validation@100 batch 60 loss 0.18306, top1 98.44%, \n",
            "2023-02-13 17:01:05,046 [INFO] train: Validation@100 batch 61 loss 0.31327, top1 89.06%, \n",
            "2023-02-13 17:01:05,137 [INFO] train: Validation@100 batch 62 loss 0.24769, top1 95.31%, \n",
            "2023-02-13 17:01:05,223 [INFO] train: Validation@100 batch 63 loss 0.22499, top1 93.75%, \n",
            "2023-02-13 17:01:05,586 [INFO] train: Validation@100 batch 64 loss 0.21591, top1 93.75%, \n",
            "2023-02-13 17:01:05,725 [INFO] train: Validation@100 batch 65 loss 0.14419, top1 98.44%, \n",
            "2023-02-13 17:01:05,807 [INFO] train: Validation@100 batch 66 loss 0.12120, top1 98.44%, \n",
            "2023-02-13 17:01:05,882 [INFO] train: Validation@100 batch 67 loss 0.27031, top1 93.75%, \n",
            "2023-02-13 17:01:05,967 [INFO] train: Validation@100 batch 68 loss 0.19939, top1 95.31%, \n",
            "2023-02-13 17:01:06,043 [INFO] train: Validation@100 batch 69 loss 0.12690, top1 98.44%, \n",
            "2023-02-13 17:01:06,119 [INFO] train: Validation@100 batch 70 loss 0.26938, top1 89.06%, \n",
            "2023-02-13 17:01:06,206 [INFO] train: Validation@100 batch 71 loss 0.30589, top1 92.19%, \n",
            "2023-02-13 17:01:06,295 [INFO] train: Validation@100 batch 72 loss 0.34912, top1 90.62%, \n",
            "2023-02-13 17:01:06,395 [INFO] train: Validation@100 batch 73 loss 0.15124, top1 96.88%, \n",
            "2023-02-13 17:01:06,473 [INFO] train: Validation@100 batch 74 loss 0.34699, top1 87.50%, \n",
            "2023-02-13 17:01:06,563 [INFO] train: Validation@100 batch 75 loss 0.18988, top1 95.31%, \n",
            "2023-02-13 17:01:06,646 [INFO] train: Validation@100 batch 76 loss 0.33157, top1 90.62%, \n",
            "2023-02-13 17:01:06,718 [INFO] train: Validation@100 batch 77 loss 0.35463, top1 90.62%, \n",
            "2023-02-13 17:01:06,808 [INFO] train: Validation@100 batch 78 loss 0.16192, top1 96.88%, \n",
            "2023-02-13 17:01:06,912 [INFO] train: Validation@100 batch 79 loss 0.22067, top1 95.31%, \n",
            "2023-02-13 17:01:07,026 [INFO] train: Validation@100 batch 80 loss 0.17661, top1 95.31%, \n",
            "2023-02-13 17:01:07,100 [INFO] train: Validation@100 batch 81 loss 0.31678, top1 89.06%, \n",
            "2023-02-13 17:01:07,248 [INFO] train: Validation@100 batch 82 loss 0.16307, top1 96.88%, \n",
            "2023-02-13 17:01:07,329 [INFO] train: Validation@100 batch 83 loss 0.23110, top1 90.62%, \n",
            "2023-02-13 17:01:07,432 [INFO] train: Validation@100 batch 84 loss 0.22003, top1 95.31%, \n",
            "2023-02-13 17:01:07,513 [INFO] train: Validation@100 batch 85 loss 0.23718, top1 92.19%, \n",
            "2023-02-13 17:01:07,639 [INFO] train: Validation@100 batch 86 loss 0.22449, top1 96.88%, \n",
            "2023-02-13 17:01:07,730 [INFO] train: Validation@100 batch 87 loss 0.28000, top1 96.88%, \n",
            "2023-02-13 17:01:07,894 [INFO] train: Validation@100 batch 88 loss 0.27702, top1 93.75%, \n",
            "2023-02-13 17:01:07,969 [INFO] train: Validation@100 batch 89 loss 0.20749, top1 93.75%, \n",
            "2023-02-13 17:01:08,062 [INFO] train: Validation@100 batch 90 loss 0.23412, top1 95.31%, \n",
            "2023-02-13 17:01:08,149 [INFO] train: Validation@100 batch 91 loss 0.38410, top1 85.94%, \n",
            "2023-02-13 17:01:08,232 [INFO] train: Validation@100 batch 92 loss 0.25455, top1 90.62%, \n",
            "2023-02-13 17:01:08,300 [INFO] train: Validation@100 batch 93 loss 0.21137, top1 96.88%, \n",
            "2023-02-13 17:01:08,407 [INFO] train: Validation@100 batch 94 loss 0.25833, top1 92.19%, \n",
            "2023-02-13 17:01:08,479 [INFO] train: Validation@100 batch 95 loss 0.13224, top1 96.88%, \n",
            "2023-02-13 17:01:08,609 [INFO] train: Validation@100 batch 96 loss 0.28652, top1 90.62%, \n",
            "2023-02-13 17:01:08,692 [INFO] train: Validation@100 batch 97 loss 0.26096, top1 93.75%, \n",
            "2023-02-13 17:01:08,774 [INFO] train: Validation@100 batch 98 loss 0.13672, top1 96.88%, \n",
            "2023-02-13 17:01:08,864 [INFO] train: Validation@100 batch 99 loss 0.25991, top1 92.19%, \n",
            "2023-02-13 17:01:08,936 [INFO] train: Validation@100 batch 100 loss 0.23839, top1 93.75%, \n",
            "2023-02-13 17:01:09,009 [INFO] train: Validation@100 batch 101 loss 0.24303, top1 92.19%, \n",
            "2023-02-13 17:01:09,078 [INFO] train: Validation@100 batch 102 loss 0.38378, top1 85.94%, \n",
            "2023-02-13 17:01:09,148 [INFO] train: Validation@100 batch 103 loss 0.15647, top1 95.31%, \n",
            "2023-02-13 17:01:09,220 [INFO] train: Validation@100 batch 104 loss 0.14960, top1 96.88%, \n",
            "2023-02-13 17:01:09,294 [INFO] train: Validation@100 batch 105 loss 0.26057, top1 93.75%, \n",
            "2023-02-13 17:01:09,374 [INFO] train: Validation@100 batch 106 loss 0.26699, top1 92.19%, \n",
            "2023-02-13 17:01:09,441 [INFO] train: Validation@100 batch 107 loss 0.20050, top1 95.31%, \n",
            "2023-02-13 17:01:09,513 [INFO] train: Validation@100 batch 108 loss 0.30291, top1 92.19%, \n",
            "2023-02-13 17:01:09,593 [INFO] train: Validation@100 batch 109 loss 0.23306, top1 95.31%, \n",
            "2023-02-13 17:01:09,684 [INFO] train: Validation@100 batch 110 loss 0.24839, top1 92.19%, \n",
            "2023-02-13 17:01:09,756 [INFO] train: Validation@100 batch 111 loss 0.27342, top1 92.19%, \n",
            "2023-02-13 17:01:09,826 [INFO] train: Validation@100 batch 112 loss 0.23039, top1 93.75%, \n",
            "2023-02-13 17:01:09,896 [INFO] train: Validation@100 batch 113 loss 0.21836, top1 95.31%, \n",
            "2023-02-13 17:01:09,966 [INFO] train: Validation@100 batch 114 loss 0.18535, top1 95.31%, \n",
            "2023-02-13 17:01:10,042 [INFO] train: Validation@100 batch 115 loss 0.34940, top1 89.06%, \n",
            "2023-02-13 17:01:10,112 [INFO] train: Validation@100 batch 116 loss 0.16086, top1 96.88%, \n",
            "2023-02-13 17:01:10,183 [INFO] train: Validation@100 batch 117 loss 0.27816, top1 92.19%, \n",
            "2023-02-13 17:01:10,270 [INFO] train: Validation@100 batch 118 loss 0.23987, top1 93.75%, \n",
            "2023-02-13 17:01:10,348 [INFO] train: Validation@100 batch 119 loss 0.25588, top1 92.19%, \n",
            "2023-02-13 17:01:10,418 [INFO] train: Validation@100 batch 120 loss 0.17524, top1 96.88%, \n",
            "2023-02-13 17:01:10,488 [INFO] train: Validation@100 batch 121 loss 0.25076, top1 93.75%, \n",
            "2023-02-13 17:01:10,558 [INFO] train: Validation@100 batch 122 loss 0.24231, top1 95.31%, \n",
            "2023-02-13 17:01:10,629 [INFO] train: Validation@100 batch 123 loss 0.17696, top1 93.75%, \n",
            "2023-02-13 17:01:10,699 [INFO] train: Validation@100 batch 124 loss 0.25992, top1 93.75%, \n",
            "2023-02-13 17:01:10,769 [INFO] train: Validation@100 batch 125 loss 0.16754, top1 98.44%, \n",
            "2023-02-13 17:01:10,848 [INFO] train: Validation@100 batch 126 loss 0.24916, top1 95.31%, \n",
            "2023-02-13 17:01:10,917 [INFO] train: Validation@100 batch 127 loss 0.29537, top1 89.06%, \n",
            "2023-02-13 17:01:10,999 [INFO] train: Validation@100 batch 128 loss 0.17433, top1 95.31%, \n",
            "2023-02-13 17:01:11,071 [INFO] train: Validation@100 batch 129 loss 0.43159, top1 84.38%, \n",
            "2023-02-13 17:01:11,142 [INFO] train: Validation@100 batch 130 loss 0.24143, top1 92.19%, \n",
            "2023-02-13 17:01:11,220 [INFO] train: Validation@100 batch 131 loss 0.30892, top1 93.75%, \n",
            "2023-02-13 17:01:11,290 [INFO] train: Validation@100 batch 132 loss 0.25066, top1 95.31%, \n",
            "2023-02-13 17:01:11,368 [INFO] train: Validation@100 batch 133 loss 0.19777, top1 93.75%, \n",
            "2023-02-13 17:01:11,448 [INFO] train: Validation@100 batch 134 loss 0.28367, top1 90.62%, \n",
            "2023-02-13 17:01:11,528 [INFO] train: Validation@100 batch 135 loss 0.20276, top1 92.19%, \n",
            "2023-02-13 17:01:11,607 [INFO] train: Validation@100 batch 136 loss 0.34445, top1 92.19%, \n",
            "2023-02-13 17:01:11,677 [INFO] train: Validation@100 batch 137 loss 0.26571, top1 93.75%, \n",
            "2023-02-13 17:01:11,748 [INFO] train: Validation@100 batch 138 loss 0.24923, top1 92.19%, \n",
            "2023-02-13 17:01:11,823 [INFO] train: Validation@100 batch 139 loss 0.22864, top1 93.75%, \n",
            "2023-02-13 17:01:11,894 [INFO] train: Validation@100 batch 140 loss 0.21541, top1 96.88%, \n",
            "2023-02-13 17:01:11,973 [INFO] train: Validation@100 batch 141 loss 0.25719, top1 92.19%, \n",
            "2023-02-13 17:01:12,046 [INFO] train: Validation@100 batch 142 loss 0.22739, top1 90.62%, \n",
            "2023-02-13 17:01:12,116 [INFO] train: Validation@100 batch 143 loss 0.14851, top1 95.31%, \n",
            "2023-02-13 17:01:12,187 [INFO] train: Validation@100 batch 144 loss 0.33598, top1 87.50%, \n",
            "2023-02-13 17:01:12,257 [INFO] train: Validation@100 batch 145 loss 0.26607, top1 93.75%, \n",
            "2023-02-13 17:01:12,341 [INFO] train: Validation@100 batch 146 loss 0.22747, top1 92.19%, \n",
            "2023-02-13 17:01:12,410 [INFO] train: Validation@100 batch 147 loss 0.23250, top1 93.75%, \n",
            "2023-02-13 17:01:12,481 [INFO] train: Validation@100 batch 148 loss 0.15203, top1 95.31%, \n",
            "2023-02-13 17:01:12,566 [INFO] train: Validation@100 batch 149 loss 0.16739, top1 95.31%, \n",
            "2023-02-13 17:01:12,635 [INFO] train: Validation@100 batch 150 loss 0.23265, top1 95.31%, \n",
            "2023-02-13 17:01:12,718 [INFO] train: Validation@100 batch 151 loss 0.20176, top1 96.88%, \n",
            "2023-02-13 17:01:12,792 [INFO] train: Validation@100 batch 152 loss 0.24310, top1 92.19%, \n",
            "2023-02-13 17:01:12,862 [INFO] train: Validation@100 batch 153 loss 0.31795, top1 89.06%, \n",
            "2023-02-13 17:01:12,931 [INFO] train: Validation@100 batch 154 loss 0.16953, top1 96.88%, \n",
            "2023-02-13 17:01:13,001 [INFO] train: Validation@100 batch 155 loss 0.22046, top1 95.31%, \n",
            "2023-02-13 17:01:13,273 [INFO] train: Validation@100 batch 156 loss 0.25038, top1 87.50%, \n",
            "2023-02-13 17:01:13,387 [INFO] train: Validation@100 loss 0.24059, top1 93.48%, top5 99.95%\n",
            "2023-02-13 17:01:14,197 [INFO] train: [step 100 (1/2)]: loss=0.241850376 (lr=2.0e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:14,414 [INFO] train: [step 100 (2/2)]: loss=0.280648679 (lr=2.0e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:14,636 [INFO] train: [step 101 (1/2)]: loss=0.293502212 (lr=2.0e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:14,852 [INFO] train: [step 101 (2/2)]: loss=0.215999290 (lr=2.0e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:15,078 [INFO] train: [step 102 (1/2)]: loss=0.162315935 (lr=2.0e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:15,293 [INFO] train: [step 102 (2/2)]: loss=0.421322346 (lr=2.0e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:15,513 [INFO] train: [step 103 (1/2)]: loss=0.808126092 (lr=2.1e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:15,725 [INFO] train: [step 103 (2/2)]: loss=0.854404569 (lr=2.1e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:15,949 [INFO] train: [step 104 (1/2)]: loss=0.207611158 (lr=2.1e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:16,172 [INFO] train: [step 104 (2/2)]: loss=0.233856082 (lr=2.1e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:16,396 [INFO] train: [step 105 (1/2)]: loss=0.337934941 (lr=2.1e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:16,615 [INFO] train: [step 105 (2/2)]: loss=0.193892285 (lr=2.1e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:16,837 [INFO] train: [step 106 (1/2)]: loss=0.232867435 (lr=2.1e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:17,057 [INFO] train: [step 106 (2/2)]: loss=0.220092639 (lr=2.1e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:17,280 [INFO] train: [step 107 (1/2)]: loss=0.240667433 (lr=2.1e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:17,500 [INFO] train: [step 107 (2/2)]: loss=0.373133242 (lr=2.1e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:17,721 [INFO] train: [step 108 (1/2)]: loss=0.318987280 (lr=2.2e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:17,948 [INFO] train: [step 108 (2/2)]: loss=0.371566772 (lr=2.2e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:18,190 [INFO] train: [step 109 (1/2)]: loss=0.222342998 (lr=2.2e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:18,392 [INFO] train: [step 109 (2/2)]: loss=0.312969089 (lr=2.2e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:18,614 [INFO] train: [step 110 (1/2)]: loss=0.608050048 (lr=2.2e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:18,833 [INFO] train: [step 110 (2/2)]: loss=0.381804824 (lr=2.2e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:19,082 [INFO] train: [step 111 (1/2)]: loss=1.765299320 (lr=2.2e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:19,287 [INFO] train: [step 111 (2/2)]: loss=1.825911999 (lr=2.2e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:19,521 [INFO] train: [step 112 (1/2)]: loss=0.317886353 (lr=2.2e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:19,749 [INFO] train: [step 112 (2/2)]: loss=0.268052071 (lr=2.2e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:19,976 [INFO] train: [step 113 (1/2)]: loss=1.355909467 (lr=2.3e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:20,223 [INFO] train: [step 113 (2/2)]: loss=1.542431951 (lr=2.3e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:20,470 [INFO] train: [step 114 (1/2)]: loss=0.343717307 (lr=2.3e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:20,671 [INFO] train: [step 114 (2/2)]: loss=0.330181718 (lr=2.3e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:20,900 [INFO] train: [step 115 (1/2)]: loss=0.208573312 (lr=2.3e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:21,145 [INFO] train: [step 115 (2/2)]: loss=0.205194026 (lr=2.3e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:21,419 [INFO] train: [step 116 (1/2)]: loss=0.268705368 (lr=2.3e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:21,612 [INFO] train: [step 116 (2/2)]: loss=0.342764974 (lr=2.3e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:21,843 [INFO] train: [step 117 (1/2)]: loss=0.189592227 (lr=2.3e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:22,058 [INFO] train: [step 117 (2/2)]: loss=0.250135094 (lr=2.3e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:22,291 [INFO] train: [step 118 (1/2)]: loss=0.156213671 (lr=2.4e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:22,508 [INFO] train: [step 118 (2/2)]: loss=0.186998382 (lr=2.4e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:22,745 [INFO] train: [step 119 (1/2)]: loss=0.109933041 (lr=2.4e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:22,955 [INFO] train: [step 119 (2/2)]: loss=0.199302778 (lr=2.4e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:23,199 [INFO] train: [step 120 (1/2)]: loss=0.242751062 (lr=2.4e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:23,414 [INFO] train: [step 120 (2/2)]: loss=0.308319360 (lr=2.4e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:23,631 [INFO] train: [step 121 (1/2)]: loss=0.295799702 (lr=2.4e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:23,976 [INFO] train: [step 121 (2/2)]: loss=0.339583039 (lr=2.4e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:24,221 [INFO] train: [step 122 (1/2)]: loss=0.196950853 (lr=2.4e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:24,521 [INFO] train: [step 122 (2/2)]: loss=0.252864331 (lr=2.4e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:24,723 [INFO] train: [step 123 (1/2)]: loss=0.748342752 (lr=2.5e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:25,011 [INFO] train: [step 123 (2/2)]: loss=0.659006774 (lr=2.5e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:25,272 [INFO] train: [step 124 (1/2)]: loss=0.157392189 (lr=2.5e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:25,515 [INFO] train: [step 124 (2/2)]: loss=0.277293801 (lr=2.5e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:25,716 [INFO] train: [step 125 (1/2)]: loss=1.548676372 (lr=2.5e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:26,022 [INFO] train: [step 125 (2/2)]: loss=1.459858537 (lr=2.5e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:26,285 [INFO] train: [step 126 (1/2)]: loss=0.318869174 (lr=2.5e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:26,522 [INFO] train: [step 126 (2/2)]: loss=0.249327153 (lr=2.5e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:26,703 [INFO] train: [step 127 (1/2)]: loss=0.286845326 (lr=2.5e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:26,935 [INFO] train: [step 127 (2/2)]: loss=0.218323663 (lr=2.5e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:27,162 [INFO] train: [step 128 (1/2)]: loss=0.394228458 (lr=2.6e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:27,390 [INFO] train: [step 128 (2/2)]: loss=0.181314081 (lr=2.6e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:27,624 [INFO] train: [step 129 (1/2)]: loss=0.279625237 (lr=2.6e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:27,848 [INFO] train: [step 129 (2/2)]: loss=0.225047648 (lr=2.6e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:28,064 [INFO] train: [step 130 (1/2)]: loss=0.224898934 (lr=2.6e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:28,299 [INFO] train: [step 130 (2/2)]: loss=0.218377814 (lr=2.6e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:28,527 [INFO] train: [step 131 (1/2)]: loss=0.551899850 (lr=2.6e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:28,750 [INFO] train: [step 131 (2/2)]: loss=0.440842986 (lr=2.6e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:28,975 [INFO] train: [step 132 (1/2)]: loss=0.241800740 (lr=2.6e-04 (val_top1=93.48%))\n",
            "2023-02-13 17:01:29,166 [INFO] train: Running validation...\n",
            "2023-02-13 17:01:29,598 [INFO] train: Validation@end batch 0 loss 0.26513, top1 92.19%, \n",
            "2023-02-13 17:01:29,681 [INFO] train: Validation@end batch 1 loss 0.13186, top1 100.00%, \n",
            "2023-02-13 17:01:29,821 [INFO] train: Validation@end batch 2 loss 0.26014, top1 89.06%, \n",
            "2023-02-13 17:01:29,897 [INFO] train: Validation@end batch 3 loss 0.24204, top1 93.75%, \n",
            "2023-02-13 17:01:30,014 [INFO] train: Validation@end batch 4 loss 0.14936, top1 95.31%, \n",
            "2023-02-13 17:01:30,111 [INFO] train: Validation@end batch 5 loss 0.20010, top1 92.19%, \n",
            "2023-02-13 17:01:30,207 [INFO] train: Validation@end batch 6 loss 0.23701, top1 90.62%, \n",
            "2023-02-13 17:01:30,295 [INFO] train: Validation@end batch 7 loss 0.22621, top1 92.19%, \n",
            "2023-02-13 17:01:30,403 [INFO] train: Validation@end batch 8 loss 0.12727, top1 96.88%, \n",
            "2023-02-13 17:01:30,477 [INFO] train: Validation@end batch 9 loss 0.20959, top1 95.31%, \n",
            "2023-02-13 17:01:30,578 [INFO] train: Validation@end batch 10 loss 0.22048, top1 95.31%, \n",
            "2023-02-13 17:01:30,658 [INFO] train: Validation@end batch 11 loss 0.25971, top1 92.19%, \n",
            "2023-02-13 17:01:30,766 [INFO] train: Validation@end batch 12 loss 0.22598, top1 93.75%, \n",
            "2023-02-13 17:01:30,849 [INFO] train: Validation@end batch 13 loss 0.22411, top1 93.75%, \n",
            "2023-02-13 17:01:30,969 [INFO] train: Validation@end batch 14 loss 0.12569, top1 96.88%, \n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!mate train bit learn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mate install https://github.com/oalee/deep-vision/tree/main/deepnet/experiments/resnet -yo pip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDMa7B_W_bWk",
        "outputId": "45de4db0-7fc1-4528-f869-fcc4ee5a4192"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing experiments/resnet from https://github.com/oalee/deep-vision/tree/main\n",
            "Downloading https://github.com/oalee/deep-vision/tree/main/deepnet/experiments/resnet\n",
            "\u001b[1m\u001b[32mDownloaded: \u001b[37m__init__.py\u001b[0m\n",
            "\u001b[1m\u001b[32mDownloaded: \u001b[37mcifar_10_resnet.py\u001b[0m\n",
            "\u001b[1m\u001b[32mDownloaded: \u001b[37mcifar_10_resnet_fine_tune.py\u001b[0m\n",
            "\u001b[1m\u001b[32mDownloaded: \u001b[37mdependencies.json\u001b[0m\n",
            "\u001b[1m\u001b[32mDownloaded: \u001b[37mrequirements.txt\u001b[0m\n",
            "\u001b[1m\u001b[32mDownloaded: \u001b[37mtune.py\u001b[0m\n",
            "\u001b[1m\u001b[32mDownloaded: \u001b[37mtune_clean.py\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting pytorch_lightning~=1.7.5\n",
            "  Downloading pytorch_lightning-1.7.7-py3-none-any.whl (708 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m708.1/708.1 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard~=2.10.0 in /usr/local/lib/python3.9/site-packages (from -r /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet/requirements.txt (line 3)) (2.10.1)\n",
            "Requirement already satisfied: timm~=0.6.12 in /usr/local/lib/python3.9/site-packages (from -r /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet/requirements.txt (line 4)) (0.6.12)\n",
            "Requirement already satisfied: torchvision~=0.13.1 in /usr/local/lib/python3.9/site-packages (from -r /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet/requirements.txt (line 5)) (0.13.1)\n",
            "Requirement already satisfied: torch~=1.12.1 in /usr/local/lib/python3.9/site-packages (from -r /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet/requirements.txt (line 6)) (1.12.1)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.9/site-packages (from pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet/requirements.txt (line 2)) (1.24.2)\n",
            "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
            "  Downloading fsspec-2023.1.0-py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.9/site-packages (from pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet/requirements.txt (line 2)) (22.0)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.9/site-packages (from pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet/requirements.txt (line 2)) (6.0)\n",
            "Collecting torchmetrics>=0.7.0\n",
            "  Downloading torchmetrics-0.11.1-py3-none-any.whl (517 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.2/517.2 kB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyDeprecate>=0.3.1\n",
            "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.9/site-packages (from pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet/requirements.txt (line 2)) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.9/site-packages (from pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet/requirements.txt (line 2)) (4.4.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.9/site-packages (from tensorboard~=2.10.0->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet/requirements.txt (line 3)) (3.19.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/site-packages (from tensorboard~=2.10.0->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet/requirements.txt (line 3)) (1.8.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.9/site-packages (from tensorboard~=2.10.0->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet/requirements.txt (line 3)) (1.51.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/site-packages (from tensorboard~=2.10.0->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet/requirements.txt (line 3)) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/site-packages (from tensorboard~=2.10.0->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet/requirements.txt (line 3)) (2.16.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/site-packages (from tensorboard~=2.10.0->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet/requirements.txt (line 3)) (2.2.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/site-packages (from tensorboard~=2.10.0->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet/requirements.txt (line 3)) (2.28.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.9/site-packages (from tensorboard~=2.10.0->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet/requirements.txt (line 3)) (51.0.0.post20201207)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.9/site-packages (from tensorboard~=2.10.0->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet/requirements.txt (line 3)) (0.36.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/site-packages (from tensorboard~=2.10.0->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet/requirements.txt (line 3)) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/site-packages (from tensorboard~=2.10.0->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet/requirements.txt (line 3)) (0.4.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.9/site-packages (from tensorboard~=2.10.0->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet/requirements.txt (line 3)) (1.4.0)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.9/site-packages (from timm~=0.6.12->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet/requirements.txt (line 4)) (0.12.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/site-packages (from torchvision~=0.13.1->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet/requirements.txt (line 5)) (9.4.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.9/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet/requirements.txt (line 2)) (3.8.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.10.0->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet/requirements.txt (line 3)) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.10.0->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet/requirements.txt (line 3)) (5.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.10.0->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet/requirements.txt (line 3)) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.10.0->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet/requirements.txt (line 3)) (0.2.7)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.10.0->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet/requirements.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard~=2.10.0->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet/requirements.txt (line 3)) (6.0.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.10.0->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet/requirements.txt (line 3)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.10.0->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet/requirements.txt (line 3)) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.10.0->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet/requirements.txt (line 3)) (1.25.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.10.0->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet/requirements.txt (line 3)) (2.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard~=2.10.0->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet/requirements.txt (line 3)) (2.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/site-packages (from huggingface-hub->timm~=0.6.12->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet/requirements.txt (line 4)) (3.9.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet/requirements.txt (line 2)) (22.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet/requirements.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet/requirements.txt (line 2)) (1.3.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet/requirements.txt (line 2)) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet/requirements.txt (line 2)) (6.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet/requirements.txt (line 2)) (1.7.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.10.0->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet/requirements.txt (line 3)) (3.13.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.10.0->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet/requirements.txt (line 3)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.10.0->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet/requirements.txt (line 3)) (3.2.2)\n",
            "Installing collected packages: pyDeprecate, fsspec, torchmetrics, pytorch_lightning\n",
            "Successfully installed fsspec-2023.1.0 pyDeprecate-0.3.2 pytorch_lightning-1.7.7 torchmetrics-0.11.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "Installing trainers/classification from https://github.com/oalee/deep-vision/tree/main\n",
            "Downloading https://github.com/oalee/deep-vision/tree/main/deepnet/trainers/classification\n",
            "\u001b[1m\u001b[32mDownloaded: \u001b[37m__init__.py\u001b[0m\n",
            "\u001b[1m\u001b[32mDownloaded: \u001b[37mpl_classification.py\u001b[0m\n",
            "\u001b[1m\u001b[32mDownloaded: \u001b[37mrequirements.txt\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: ipdb~=0.13.9 in /usr/local/lib/python3.9/site-packages (from -r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 2)) (0.13.11)\n",
            "Requirement already satisfied: pytorch_lightning~=1.7.5 in /usr/local/lib/python3.9/site-packages (from -r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 3)) (1.7.7)\n",
            "Collecting torchmetrics~=0.9.3\n",
            "  Downloading torchmetrics-0.9.3-py3-none-any.whl (419 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m419.6/419.6 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch~=1.12.1 in /usr/local/lib/python3.9/site-packages (from -r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 5)) (1.12.1)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.9/site-packages (from ipdb~=0.13.9->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 2)) (2.0.1)\n",
            "Requirement already satisfied: ipython>=7.31.1 in /usr/local/lib/python3.9/site-packages (from ipdb~=0.13.9->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 2)) (8.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/site-packages (from ipdb~=0.13.9->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 2)) (5.1.1)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.9/site-packages (from pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 3)) (1.24.2)\n",
            "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.9/site-packages (from pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 3)) (2023.1.0)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.9/site-packages (from pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 3)) (2.10.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.9/site-packages (from pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 3)) (22.0)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.9/site-packages (from pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 3)) (4.64.1)\n",
            "Requirement already satisfied: pyDeprecate>=0.3.1 in /usr/local/lib/python3.9/site-packages (from pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 3)) (0.3.2)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.9/site-packages (from pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 3)) (4.4.0)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.9/site-packages (from pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 3)) (6.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.9/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 3)) (3.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 3)) (2.28.2)\n",
            "Requirement already satisfied: stack-data in /usr/local/lib/python3.9/site-packages (from ipython>=7.31.1->ipdb~=0.13.9->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 2)) (0.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.9/site-packages (from ipython>=7.31.1->ipdb~=0.13.9->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 2)) (0.18.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/site-packages (from ipython>=7.31.1->ipdb~=0.13.9->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 2)) (0.7.5)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.9/site-packages (from ipython>=7.31.1->ipdb~=0.13.9->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 2)) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/site-packages (from ipython>=7.31.1->ipdb~=0.13.9->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 2)) (3.0.36)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.9/site-packages (from ipython>=7.31.1->ipdb~=0.13.9->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 2)) (0.1.6)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.9/site-packages (from ipython>=7.31.1->ipdb~=0.13.9->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 2)) (2.14.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.9/site-packages (from ipython>=7.31.1->ipdb~=0.13.9->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 2)) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=5 in /usr/local/lib/python3.9/site-packages (from ipython>=7.31.1->ipdb~=0.13.9->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 2)) (5.7.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/site-packages (from tensorboard>=2.9.1->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 3)) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/site-packages (from tensorboard>=2.9.1->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 3)) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/site-packages (from tensorboard>=2.9.1->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 3)) (2.16.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/site-packages (from tensorboard>=2.9.1->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 3)) (2.2.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/site-packages (from tensorboard>=2.9.1->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 3)) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/site-packages (from tensorboard>=2.9.1->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 3)) (3.4.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.9/site-packages (from tensorboard>=2.9.1->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 3)) (1.4.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.9/site-packages (from tensorboard>=2.9.1->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 3)) (51.0.0.post20201207)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.9/site-packages (from tensorboard>=2.9.1->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 3)) (1.51.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.9/site-packages (from tensorboard>=2.9.1->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 3)) (0.36.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.9/site-packages (from tensorboard>=2.9.1->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 3)) (3.19.6)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 3)) (22.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 3)) (1.7.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 3)) (4.0.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 3)) (2.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 3)) (6.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 3)) (1.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 3)) (0.2.7)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 3)) (1.15.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 3)) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 3)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/site-packages (from jedi>=0.16->ipython>=7.31.1->ipdb~=0.13.9->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 2)) (0.8.3)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard>=2.9.1->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 3)) (6.0.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.9/site-packages (from pexpect>4.3->ipython>=7.31.1->ipdb~=0.13.9->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 2)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/site-packages (from prompt-toolkit<3.1.0,>=3.0.11->ipython>=7.31.1->ipdb~=0.13.9->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 2)) (0.2.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 3)) (1.25.11)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 3)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 3)) (2022.12.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 3)) (2.1.1)\n",
            "Requirement already satisfied: pure-eval in /usr/local/lib/python3.9/site-packages (from stack-data->ipython>=7.31.1->ipdb~=0.13.9->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 2)) (0.2.2)\n",
            "Requirement already satisfied: executing in /usr/local/lib/python3.9/site-packages (from stack-data->ipython>=7.31.1->ipdb~=0.13.9->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 2)) (0.8.3)\n",
            "Requirement already satisfied: asttokens in /usr/local/lib/python3.9/site-packages (from stack-data->ipython>=7.31.1->ipdb~=0.13.9->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 2)) (2.0.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.9.1->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 3)) (3.13.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 3)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification/requirements.txt (line 3)) (3.2.2)\n",
            "Installing collected packages: torchmetrics\n",
            "  Attempting uninstall: torchmetrics\n",
            "    Found existing installation: torchmetrics 0.11.1\n",
            "    Uninstalling torchmetrics-0.11.1:\n",
            "      Successfully uninstalled torchmetrics-0.11.1\n",
            "Successfully installed torchmetrics-0.9.3\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "Module installed at /content/drive/MyDrive/deeplearning_project/deeplearning_project/trainers/classification\n",
            "Installing models/resnet from https://github.com/oalee/deep-vision/tree/main\n",
            "Downloading https://github.com/oalee/deep-vision/tree/main/deepnet/models/resnet\n",
            "\u001b[1m\u001b[32mDownloaded: \u001b[37m__init__.py\u001b[0m\n",
            "\u001b[1m\u001b[32mDownloaded: \u001b[37mrequirements.txt\u001b[0m\n",
            "\u001b[1m\u001b[32mDownloaded: \u001b[37mCOPYRIGHT\u001b[0m\n",
            "\u001b[1m\u001b[32mDownloaded: \u001b[37mLICENSE\u001b[0m\n",
            "\u001b[1m\u001b[32mDownloaded: \u001b[37m__init__.py\u001b[0m\n",
            "\u001b[1m\u001b[32mDownloaded: \u001b[37mfine_tune.py\u001b[0m\n",
            "\u001b[1m\u001b[32mDownloaded: \u001b[37mrequirements.txt\u001b[0m\n",
            "\u001b[1m\u001b[32mDownloaded: \u001b[37mresnet.py\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: torch~=1.12.1 in /usr/local/lib/python3.9/site-packages (from -r /content/drive/MyDrive/deeplearning_project/deeplearning_project/models/resnet/requirements.txt (line 2)) (1.12.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/site-packages (from torch~=1.12.1->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/models/resnet/requirements.txt (line 2)) (4.4.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "Module installed at /content/drive/MyDrive/deeplearning_project/deeplearning_project/models/resnet\n",
            "Installing data/cifar10 from https://github.com/oalee/deep-vision/tree/main\n",
            "Downloading https://github.com/oalee/deep-vision/tree/main/deepnet/data/cifar10\n",
            "\u001b[1m\u001b[32mDownloaded: \u001b[37m__init__.py\u001b[0m\n",
            "\u001b[1m\u001b[32mDownloaded: \u001b[37mdata_loader.py\u001b[0m\n",
            "\u001b[1m\u001b[32mDownloaded: \u001b[37mrequirements.txt\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: ipdb~=0.13.9 in /usr/local/lib/python3.9/site-packages (from -r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 2)) (0.13.11)\n",
            "Requirement already satisfied: torch~=1.12.1 in /usr/local/lib/python3.9/site-packages (from -r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 3)) (1.12.1)\n",
            "Requirement already satisfied: pytorch_lightning~=1.7.5 in /usr/local/lib/python3.9/site-packages (from -r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 4)) (1.7.7)\n",
            "Requirement already satisfied: torchvision~=0.13.1 in /usr/local/lib/python3.9/site-packages (from -r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 5)) (0.13.1)\n",
            "Requirement already satisfied: ipython>=7.31.1 in /usr/local/lib/python3.9/site-packages (from ipdb~=0.13.9->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 2)) (8.8.0)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.9/site-packages (from ipdb~=0.13.9->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 2)) (2.0.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/site-packages (from ipdb~=0.13.9->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 2)) (5.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/site-packages (from torch~=1.12.1->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 3)) (4.4.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.9/site-packages (from pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 4)) (22.0)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.9/site-packages (from pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 4)) (0.9.3)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.9/site-packages (from pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 4)) (4.64.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.9/site-packages (from pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 4)) (6.0)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.9/site-packages (from pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 4)) (2.10.1)\n",
            "Requirement already satisfied: pyDeprecate>=0.3.1 in /usr/local/lib/python3.9/site-packages (from pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 4)) (0.3.2)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.9/site-packages (from pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 4)) (1.24.2)\n",
            "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.9/site-packages (from pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 4)) (2023.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/site-packages (from torchvision~=0.13.1->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 5)) (2.28.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/site-packages (from torchvision~=0.13.1->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 5)) (9.4.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.9/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 4)) (3.8.1)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.9/site-packages (from ipython>=7.31.1->ipdb~=0.13.9->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 2)) (2.14.0)\n",
            "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/site-packages (from ipython>=7.31.1->ipdb~=0.13.9->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 2)) (3.0.36)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.9/site-packages (from ipython>=7.31.1->ipdb~=0.13.9->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 2)) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/site-packages (from ipython>=7.31.1->ipdb~=0.13.9->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 2)) (0.7.5)\n",
            "Requirement already satisfied: stack-data in /usr/local/lib/python3.9/site-packages (from ipython>=7.31.1->ipdb~=0.13.9->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 2)) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=5 in /usr/local/lib/python3.9/site-packages (from ipython>=7.31.1->ipdb~=0.13.9->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 2)) (5.7.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.9/site-packages (from ipython>=7.31.1->ipdb~=0.13.9->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 2)) (0.18.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.9/site-packages (from ipython>=7.31.1->ipdb~=0.13.9->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 2)) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.9/site-packages (from ipython>=7.31.1->ipdb~=0.13.9->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 2)) (0.1.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.9/site-packages (from tensorboard>=2.9.1->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 4)) (1.51.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/site-packages (from tensorboard>=2.9.1->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 4)) (0.4.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.9/site-packages (from tensorboard>=2.9.1->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 4)) (0.36.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.9/site-packages (from tensorboard>=2.9.1->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 4)) (3.19.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/site-packages (from tensorboard>=2.9.1->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 4)) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/site-packages (from tensorboard>=2.9.1->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 4)) (2.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/site-packages (from tensorboard>=2.9.1->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 4)) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/site-packages (from tensorboard>=2.9.1->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 4)) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/site-packages (from tensorboard>=2.9.1->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 4)) (2.2.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.9/site-packages (from tensorboard>=2.9.1->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 4)) (51.0.0.post20201207)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.9/site-packages (from tensorboard>=2.9.1->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 4)) (1.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests->torchvision~=0.13.1->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 5)) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests->torchvision~=0.13.1->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 5)) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/site-packages (from requests->torchvision~=0.13.1->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 5)) (2.1.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests->torchvision~=0.13.1->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 5)) (1.25.11)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 4)) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 4)) (1.7.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 4)) (1.3.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 4)) (6.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 4)) (22.1.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 4)) (0.2.7)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 4)) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 4)) (4.9)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 4)) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/site-packages (from jedi>=0.16->ipython>=7.31.1->ipdb~=0.13.9->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 2)) (0.8.3)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard>=2.9.1->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 4)) (6.0.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.9/site-packages (from pexpect>4.3->ipython>=7.31.1->ipdb~=0.13.9->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 2)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/site-packages (from prompt-toolkit<3.1.0,>=3.0.11->ipython>=7.31.1->ipdb~=0.13.9->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 2)) (0.2.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 4)) (2.1.1)\n",
            "Requirement already satisfied: pure-eval in /usr/local/lib/python3.9/site-packages (from stack-data->ipython>=7.31.1->ipdb~=0.13.9->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 2)) (0.2.2)\n",
            "Requirement already satisfied: executing in /usr/local/lib/python3.9/site-packages (from stack-data->ipython>=7.31.1->ipdb~=0.13.9->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 2)) (0.8.3)\n",
            "Requirement already satisfied: asttokens in /usr/local/lib/python3.9/site-packages (from stack-data->ipython>=7.31.1->ipdb~=0.13.9->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 2)) (2.0.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.9.1->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 4)) (3.13.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 4)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch_lightning~=1.7.5->-r /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10/requirements.txt (line 4)) (3.2.2)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "Module installed at /content/drive/MyDrive/deeplearning_project/deeplearning_project/data/cifar10\n",
            "Module installed at /content/drive/MyDrive/deeplearning_project/deeplearning_project/experiments/resnet\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mate summary"
      ],
      "metadata": {
        "id": "72qRZTBPu22E",
        "outputId": "3ec781a2-73b3-4369-afe0-b70679449742",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"models\": [\n",
            "        \"bit_torch\",\n",
            "        \"resnet\"\n",
            "    ],\n",
            "    \"trainers\": [\n",
            "        \"bit_torch\",\n",
            "        \"classification\"\n",
            "    ],\n",
            "    \"data\": [\n",
            "        \"bit\",\n",
            "        \"cifar10\"\n",
            "    ],\n",
            "    \"experiments\": {\n",
            "        \"bit\": [\n",
            "            \"learn.py\"\n",
            "        ],\n",
            "        \"resnet\": [\n",
            "            \"cifar_10_resnet.py\",\n",
            "            \"cifar_10_resnet_fine_tune.py\",\n",
            "            \"tune.py\",\n",
            "            \"tune_clean.py\"\n",
            "        ]\n",
            "    }\n",
            "}\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mate train resnet tune"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLVddsA1CDxW",
        "outputId": "0bf33cfa-2142-48a4-e3b9-401fe78fdcb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Using 16bit native Automatic Mixed Precision (AMP)\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:616: UserWarning: Checkpoint directory /content/drive/MyDrive/deepnet/resnet/tune exists and is not empty.\n",
            "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name           | Type             | Params\n",
            "----------------------------------------------------\n",
            "0 | criterion      | CrossEntropyLoss | 0     \n",
            "1 | classifier     | ResNetTuneModel  | 21.3 M\n",
            "2 | train_accuracy | Accuracy         | 0     \n",
            "3 | val_accuracy   | Accuracy         | 0     \n",
            "----------------------------------------------------\n",
            "21.3 M    Trainable params\n",
            "0         Non-trainable params\n",
            "21.3 M    Total params\n",
            "42.580    Total estimated model params size (MB)\n",
            "Epoch 0:  83% 391/470 [00:55<00:11,  7.10it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 0:  83% 392/470 [00:55<00:11,  7.08it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  84% 393/470 [00:55<00:10,  7.10it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  84% 394/470 [00:55<00:10,  7.11it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  84% 395/470 [00:55<00:10,  7.13it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  84% 396/470 [00:55<00:10,  7.14it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  84% 397/470 [00:55<00:10,  7.15it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  85% 398/470 [00:55<00:10,  7.16it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  85% 399/470 [00:55<00:09,  7.17it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  85% 400/470 [00:55<00:09,  7.18it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  85% 401/470 [00:55<00:09,  7.20it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  86% 402/470 [00:55<00:09,  7.21it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  86% 403/470 [00:55<00:09,  7.22it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  86% 404/470 [00:55<00:09,  7.23it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  86% 405/470 [00:55<00:08,  7.24it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  86% 406/470 [00:55<00:08,  7.26it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  87% 407/470 [00:55<00:08,  7.27it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  87% 408/470 [00:56<00:08,  7.28it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  87% 409/470 [00:56<00:08,  7.30it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  87% 410/470 [00:56<00:08,  7.30it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  87% 411/470 [00:56<00:08,  7.32it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  88% 412/470 [00:56<00:07,  7.33it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  88% 413/470 [00:56<00:07,  7.34it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  88% 414/470 [00:56<00:07,  7.36it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  88% 415/470 [00:56<00:07,  7.37it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  89% 416/470 [00:56<00:07,  7.38it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  89% 417/470 [00:56<00:07,  7.39it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  89% 418/470 [00:56<00:07,  7.40it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  89% 419/470 [00:56<00:06,  7.41it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  89% 420/470 [00:56<00:06,  7.43it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  90% 421/470 [00:56<00:06,  7.44it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  90% 422/470 [00:56<00:06,  7.45it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  90% 423/470 [00:56<00:06,  7.47it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  90% 424/470 [00:56<00:06,  7.47it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  90% 425/470 [00:56<00:06,  7.49it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  91% 426/470 [00:56<00:05,  7.50it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  91% 427/470 [00:56<00:05,  7.51it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  91% 428/470 [00:56<00:05,  7.52it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  91% 429/470 [00:56<00:05,  7.54it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  91% 430/470 [00:56<00:05,  7.55it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  92% 431/470 [00:57<00:05,  7.56it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  92% 432/470 [00:57<00:05,  7.57it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  92% 433/470 [00:57<00:04,  7.58it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  92% 434/470 [00:57<00:04,  7.59it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  93% 435/470 [00:57<00:04,  7.60it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  93% 436/470 [00:57<00:04,  7.62it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  93% 437/470 [00:57<00:04,  7.63it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  93% 438/470 [00:57<00:04,  7.63it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  93% 439/470 [00:57<00:04,  7.65it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  94% 440/470 [00:57<00:03,  7.66it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  94% 441/470 [00:57<00:03,  7.67it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  94% 442/470 [00:57<00:03,  7.68it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  94% 443/470 [00:57<00:03,  7.69it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  94% 444/470 [00:57<00:03,  7.70it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  95% 445/470 [00:57<00:03,  7.71it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  95% 446/470 [00:57<00:03,  7.71it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  95% 447/470 [00:57<00:02,  7.72it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  95% 448/470 [00:57<00:02,  7.73it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  96% 449/470 [00:57<00:02,  7.75it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  96% 450/470 [00:58<00:02,  7.75it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  96% 451/470 [00:58<00:02,  7.76it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  96% 452/470 [00:58<00:02,  7.77it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  96% 453/470 [00:58<00:02,  7.78it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  97% 454/470 [00:58<00:02,  7.78it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  97% 455/470 [00:58<00:01,  7.79it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  97% 456/470 [00:58<00:01,  7.80it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  97% 457/470 [00:58<00:01,  7.82it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  97% 458/470 [00:58<00:01,  7.82it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  98% 459/470 [00:58<00:01,  7.83it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  98% 460/470 [00:58<00:01,  7.83it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  98% 461/470 [00:58<00:01,  7.83it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  98% 462/470 [00:58<00:01,  7.84it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  99% 463/470 [00:59<00:00,  7.85it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  99% 464/470 [00:59<00:00,  7.85it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  99% 465/470 [00:59<00:00,  7.85it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  99% 466/470 [00:59<00:00,  7.86it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0:  99% 467/470 [00:59<00:00,  7.88it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0: 100% 468/470 [00:59<00:00,  7.89it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0: 100% 469/470 [00:59<00:00,  7.90it/s, loss=0.684, v_num=3, train_accuracy=0.684]\n",
            "Epoch 0: 100% 470/470 [00:59<00:00,  7.92it/s, loss=0.684, v_num=3, train_accuracy=0.684, val_accuracy=0.767]\n",
            "Epoch 1:  83% 391/470 [01:01<00:12,  6.37it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1:  83% 392/470 [01:01<00:12,  6.36it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  84% 393/470 [01:01<00:12,  6.37it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  84% 394/470 [01:01<00:11,  6.39it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  84% 395/470 [01:01<00:11,  6.40it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  84% 396/470 [01:01<00:11,  6.41it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  84% 397/470 [01:01<00:11,  6.42it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  85% 398/470 [01:01<00:11,  6.43it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  85% 399/470 [01:01<00:11,  6.45it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  85% 400/470 [01:01<00:10,  6.46it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  85% 401/470 [01:01<00:10,  6.47it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  86% 402/470 [01:02<00:10,  6.48it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  86% 403/470 [01:02<00:10,  6.49it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  86% 404/470 [01:02<00:10,  6.50it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  86% 405/470 [01:02<00:09,  6.51it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  86% 406/470 [01:02<00:09,  6.52it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  87% 407/470 [01:02<00:09,  6.54it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  87% 408/470 [01:02<00:09,  6.55it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  87% 409/470 [01:02<00:09,  6.56it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  87% 410/470 [01:02<00:09,  6.57it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  87% 411/470 [01:02<00:08,  6.58it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  88% 412/470 [01:02<00:08,  6.60it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  88% 413/470 [01:02<00:08,  6.61it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  88% 414/470 [01:02<00:08,  6.62it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  88% 415/470 [01:02<00:08,  6.63it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  89% 416/470 [01:02<00:08,  6.64it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  89% 417/470 [01:02<00:07,  6.65it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  89% 418/470 [01:02<00:07,  6.67it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  89% 419/470 [01:02<00:07,  6.68it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  89% 420/470 [01:02<00:07,  6.69it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  90% 421/470 [01:02<00:07,  6.70it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  90% 422/470 [01:02<00:07,  6.71it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  90% 423/470 [01:02<00:06,  6.72it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  90% 424/470 [01:02<00:06,  6.73it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  90% 425/470 [01:03<00:06,  6.74it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  91% 426/470 [01:03<00:06,  6.76it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  91% 427/470 [01:03<00:06,  6.77it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  91% 428/470 [01:03<00:06,  6.78it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  91% 429/470 [01:03<00:06,  6.79it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  91% 430/470 [01:03<00:05,  6.80it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  92% 431/470 [01:03<00:05,  6.81it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  92% 432/470 [01:03<00:05,  6.82it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  92% 433/470 [01:03<00:05,  6.83it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  92% 434/470 [01:03<00:05,  6.84it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  93% 435/470 [01:03<00:05,  6.85it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  93% 436/470 [01:03<00:04,  6.86it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  93% 437/470 [01:03<00:04,  6.88it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  93% 438/470 [01:03<00:04,  6.89it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  93% 439/470 [01:03<00:04,  6.90it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  94% 440/470 [01:03<00:04,  6.91it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  94% 441/470 [01:03<00:04,  6.92it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  94% 442/470 [01:03<00:04,  6.93it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  94% 443/470 [01:03<00:03,  6.94it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  94% 444/470 [01:03<00:03,  6.95it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  95% 445/470 [01:03<00:03,  6.96it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  95% 446/470 [01:03<00:03,  6.98it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  95% 447/470 [01:04<00:03,  6.98it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  95% 448/470 [01:04<00:03,  7.00it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  96% 449/470 [01:04<00:02,  7.00it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  96% 450/470 [01:04<00:02,  7.01it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  96% 451/470 [01:04<00:02,  7.02it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  96% 452/470 [01:04<00:02,  7.04it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  96% 453/470 [01:04<00:02,  7.05it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  97% 454/470 [01:04<00:02,  7.06it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  97% 455/470 [01:04<00:02,  7.07it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  97% 456/470 [01:04<00:01,  7.08it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  97% 457/470 [01:04<00:01,  7.09it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  97% 458/470 [01:04<00:01,  7.10it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  98% 459/470 [01:04<00:01,  7.11it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  98% 460/470 [01:04<00:01,  7.12it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  98% 461/470 [01:04<00:01,  7.13it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  98% 462/470 [01:04<00:01,  7.15it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  99% 463/470 [01:04<00:00,  7.15it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  99% 464/470 [01:04<00:00,  7.17it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  99% 465/470 [01:04<00:00,  7.18it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  99% 466/470 [01:04<00:00,  7.19it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1:  99% 467/470 [01:04<00:00,  7.20it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1: 100% 468/470 [01:04<00:00,  7.21it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1: 100% 469/470 [01:04<00:00,  7.22it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.767]\n",
            "Epoch 1: 100% 470/470 [01:04<00:00,  7.23it/s, loss=0.591, v_num=3, train_accuracy=0.791, val_accuracy=0.807]\n",
            "Epoch 2:  83% 391/470 [01:06<00:13,  5.92it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2:  83% 392/470 [01:06<00:13,  5.90it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  84% 393/470 [01:06<00:13,  5.91it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  84% 394/470 [01:06<00:12,  5.92it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  84% 395/470 [01:06<00:12,  5.93it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  84% 396/470 [01:06<00:12,  5.93it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  84% 397/470 [01:06<00:12,  5.94it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  85% 398/470 [01:06<00:12,  5.95it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  85% 399/470 [01:06<00:11,  5.96it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  85% 400/470 [01:07<00:11,  5.97it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  85% 401/470 [01:07<00:11,  5.98it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  86% 402/470 [01:07<00:11,  5.98it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  86% 403/470 [01:07<00:11,  5.99it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  86% 404/470 [01:07<00:11,  5.99it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  86% 405/470 [01:07<00:10,  6.01it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  86% 406/470 [01:07<00:10,  6.01it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  87% 407/470 [01:07<00:10,  6.03it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  87% 408/470 [01:07<00:10,  6.03it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  87% 409/470 [01:07<00:10,  6.04it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  87% 410/470 [01:07<00:09,  6.05it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  87% 411/470 [01:07<00:09,  6.06it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  88% 412/470 [01:07<00:09,  6.06it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  88% 413/470 [01:08<00:09,  6.07it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  88% 414/470 [01:08<00:09,  6.08it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  88% 415/470 [01:08<00:09,  6.09it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  89% 416/470 [01:08<00:08,  6.10it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  89% 417/470 [01:08<00:08,  6.10it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  89% 418/470 [01:08<00:08,  6.11it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  89% 419/470 [01:08<00:08,  6.12it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  89% 420/470 [01:08<00:08,  6.13it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  90% 421/470 [01:08<00:07,  6.14it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  90% 422/470 [01:08<00:07,  6.14it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  90% 423/470 [01:08<00:07,  6.16it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  90% 424/470 [01:08<00:07,  6.16it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  90% 425/470 [01:08<00:07,  6.17it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  91% 426/470 [01:08<00:07,  6.18it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  91% 427/470 [01:09<00:06,  6.19it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  91% 428/470 [01:09<00:06,  6.19it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  91% 429/470 [01:09<00:06,  6.21it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  91% 430/470 [01:09<00:06,  6.21it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  92% 431/470 [01:09<00:06,  6.22it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  92% 432/470 [01:09<00:06,  6.23it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  92% 433/470 [01:09<00:05,  6.24it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  92% 434/470 [01:09<00:05,  6.25it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  93% 435/470 [01:09<00:05,  6.26it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  93% 436/470 [01:09<00:05,  6.26it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  93% 437/470 [01:09<00:05,  6.27it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  93% 438/470 [01:09<00:05,  6.28it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  93% 439/470 [01:09<00:04,  6.29it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  94% 440/470 [01:09<00:04,  6.29it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  94% 441/470 [01:09<00:04,  6.30it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  94% 442/470 [01:10<00:04,  6.31it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  94% 443/470 [01:10<00:04,  6.32it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  94% 444/470 [01:10<00:04,  6.32it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  95% 445/470 [01:10<00:03,  6.33it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  95% 446/470 [01:10<00:03,  6.33it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  95% 447/470 [01:10<00:03,  6.35it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  95% 448/470 [01:10<00:03,  6.35it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  96% 449/470 [01:10<00:03,  6.36it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  96% 450/470 [01:10<00:03,  6.37it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  96% 451/470 [01:10<00:02,  6.38it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  96% 452/470 [01:10<00:02,  6.39it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  96% 453/470 [01:10<00:02,  6.40it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  97% 454/470 [01:10<00:02,  6.41it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  97% 455/470 [01:10<00:02,  6.42it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  97% 456/470 [01:10<00:02,  6.43it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  97% 457/470 [01:10<00:02,  6.44it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  97% 458/470 [01:11<00:01,  6.45it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  98% 459/470 [01:11<00:01,  6.46it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  98% 460/470 [01:11<00:01,  6.47it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  98% 461/470 [01:11<00:01,  6.48it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  98% 462/470 [01:11<00:01,  6.49it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  99% 463/470 [01:11<00:01,  6.50it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  99% 464/470 [01:11<00:00,  6.51it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  99% 465/470 [01:11<00:00,  6.52it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  99% 466/470 [01:11<00:00,  6.53it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2:  99% 467/470 [01:11<00:00,  6.54it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2: 100% 468/470 [01:11<00:00,  6.55it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2: 100% 469/470 [01:11<00:00,  6.56it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.807]\n",
            "Epoch 2: 100% 470/470 [01:11<00:00,  6.58it/s, loss=0.505, v_num=3, train_accuracy=0.826, val_accuracy=0.821]\n",
            "Epoch 3:  83% 391/470 [00:58<00:11,  6.71it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 3:  83% 392/470 [00:58<00:11,  6.68it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  84% 393/470 [00:58<00:11,  6.69it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  84% 394/470 [00:58<00:11,  6.70it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  84% 395/470 [00:58<00:11,  6.71it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  84% 396/470 [00:58<00:11,  6.72it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  84% 397/470 [00:59<00:10,  6.73it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  85% 398/470 [00:59<00:10,  6.74it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  85% 399/470 [00:59<00:10,  6.74it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  85% 400/470 [00:59<00:10,  6.76it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  85% 401/470 [00:59<00:10,  6.76it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  86% 402/470 [00:59<00:10,  6.77it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  86% 403/470 [00:59<00:09,  6.78it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  86% 404/470 [00:59<00:09,  6.79it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  86% 405/470 [00:59<00:09,  6.80it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  86% 406/470 [00:59<00:09,  6.81it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  87% 407/470 [00:59<00:09,  6.81it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  87% 408/470 [00:59<00:09,  6.82it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  87% 409/470 [00:59<00:08,  6.83it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  87% 410/470 [00:59<00:08,  6.84it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  87% 411/470 [00:59<00:08,  6.85it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  88% 412/470 [01:00<00:08,  6.86it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  88% 413/470 [01:00<00:08,  6.87it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  88% 414/470 [01:00<00:08,  6.88it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  88% 415/470 [01:00<00:07,  6.89it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  89% 416/470 [01:00<00:07,  6.89it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  89% 417/470 [01:00<00:07,  6.90it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  89% 418/470 [01:00<00:07,  6.91it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  89% 419/470 [01:00<00:07,  6.92it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  89% 420/470 [01:00<00:07,  6.92it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  90% 421/470 [01:00<00:07,  6.94it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  90% 422/470 [01:00<00:06,  6.94it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  90% 423/470 [01:00<00:06,  6.95it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  90% 424/470 [01:00<00:06,  6.96it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  90% 425/470 [01:00<00:06,  6.97it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  91% 426/470 [01:01<00:06,  6.98it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  91% 427/470 [01:01<00:06,  6.99it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  91% 428/470 [01:01<00:06,  6.99it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  91% 429/470 [01:01<00:05,  7.01it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  91% 430/470 [01:01<00:05,  7.01it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  92% 431/470 [01:01<00:05,  7.02it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  92% 432/470 [01:01<00:05,  7.03it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  92% 433/470 [01:01<00:05,  7.04it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  92% 434/470 [01:01<00:05,  7.05it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  93% 435/470 [01:01<00:04,  7.06it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  93% 436/470 [01:01<00:04,  7.06it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  93% 437/470 [01:01<00:04,  7.07it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  93% 438/470 [01:01<00:04,  7.07it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  93% 439/470 [01:01<00:04,  7.09it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  94% 440/470 [01:02<00:04,  7.09it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  94% 441/470 [01:02<00:04,  7.10it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  94% 442/470 [01:02<00:03,  7.10it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  94% 443/470 [01:02<00:03,  7.12it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  94% 444/470 [01:02<00:03,  7.12it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  95% 445/470 [01:02<00:03,  7.13it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  95% 446/470 [01:02<00:03,  7.14it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  95% 447/470 [01:02<00:03,  7.15it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  95% 448/470 [01:02<00:03,  7.15it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  96% 449/470 [01:02<00:02,  7.16it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  96% 450/470 [01:02<00:02,  7.16it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  96% 451/470 [01:02<00:02,  7.17it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  96% 452/470 [01:02<00:02,  7.18it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  96% 453/470 [01:03<00:02,  7.19it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  97% 454/470 [01:03<00:02,  7.19it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  97% 455/470 [01:03<00:02,  7.20it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  97% 456/470 [01:03<00:01,  7.21it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  97% 457/470 [01:03<00:01,  7.22it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  97% 458/470 [01:03<00:01,  7.22it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  98% 459/470 [01:03<00:01,  7.23it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  98% 460/470 [01:03<00:01,  7.23it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  98% 461/470 [01:03<00:01,  7.25it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  98% 462/470 [01:03<00:01,  7.25it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  99% 463/470 [01:03<00:00,  7.26it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  99% 464/470 [01:03<00:00,  7.27it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  99% 465/470 [01:03<00:00,  7.28it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  99% 466/470 [01:03<00:00,  7.28it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3:  99% 467/470 [01:04<00:00,  7.30it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3: 100% 468/470 [01:04<00:00,  7.30it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3: 100% 469/470 [01:04<00:00,  7.32it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.821]\n",
            "Epoch 3: 100% 470/470 [01:04<00:00,  7.33it/s, loss=0.432, v_num=3, train_accuracy=0.847, val_accuracy=0.831]\n",
            "Epoch 4:  83% 391/470 [01:00<00:12,  6.51it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 4:  83% 392/470 [01:00<00:12,  6.49it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  84% 393/470 [01:00<00:11,  6.50it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  84% 394/470 [01:00<00:11,  6.52it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  84% 395/470 [01:00<00:11,  6.53it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  84% 396/470 [01:00<00:11,  6.54it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  84% 397/470 [01:00<00:11,  6.56it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  85% 398/470 [01:00<00:10,  6.57it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  85% 399/470 [01:00<00:10,  6.58it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  85% 400/470 [01:00<00:10,  6.59it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  85% 401/470 [01:00<00:10,  6.60it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  86% 402/470 [01:00<00:10,  6.61it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  86% 403/470 [01:00<00:10,  6.62it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  86% 404/470 [01:00<00:09,  6.64it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  86% 405/470 [01:00<00:09,  6.64it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  86% 406/470 [01:00<00:09,  6.66it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  87% 407/470 [01:01<00:09,  6.67it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  87% 408/470 [01:01<00:09,  6.68it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  87% 409/470 [01:01<00:09,  6.69it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  87% 410/470 [01:01<00:08,  6.70it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  87% 411/470 [01:01<00:08,  6.71it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  88% 412/470 [01:01<00:08,  6.73it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  88% 413/470 [01:01<00:08,  6.73it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  88% 414/470 [01:01<00:08,  6.75it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  88% 415/470 [01:01<00:08,  6.76it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  89% 416/470 [01:01<00:07,  6.77it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  89% 417/470 [01:01<00:07,  6.78it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  89% 418/470 [01:01<00:07,  6.79it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  89% 419/470 [01:01<00:07,  6.81it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  89% 420/470 [01:01<00:07,  6.82it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  90% 421/470 [01:01<00:07,  6.83it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  90% 422/470 [01:01<00:07,  6.84it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  90% 423/470 [01:01<00:06,  6.85it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  90% 424/470 [01:01<00:06,  6.86it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  90% 425/470 [01:01<00:06,  6.87it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  91% 426/470 [01:01<00:06,  6.89it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  91% 427/470 [01:01<00:06,  6.89it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  91% 428/470 [01:01<00:06,  6.91it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  91% 429/470 [01:02<00:05,  6.92it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  91% 430/470 [01:02<00:05,  6.93it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  92% 431/470 [01:02<00:05,  6.94it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  92% 432/470 [01:02<00:05,  6.95it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  92% 433/470 [01:02<00:05,  6.96it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  92% 434/470 [01:02<00:05,  6.97it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  93% 435/470 [01:02<00:05,  6.99it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  93% 436/470 [01:02<00:04,  7.00it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  93% 437/470 [01:02<00:04,  7.01it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  93% 438/470 [01:02<00:04,  7.02it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  93% 439/470 [01:02<00:04,  7.03it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  94% 440/470 [01:02<00:04,  7.04it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  94% 441/470 [01:02<00:04,  7.05it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  94% 442/470 [01:02<00:03,  7.07it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  94% 443/470 [01:02<00:03,  7.08it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  94% 444/470 [01:02<00:03,  7.09it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  95% 445/470 [01:02<00:03,  7.10it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  95% 446/470 [01:02<00:03,  7.11it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  95% 447/470 [01:02<00:03,  7.12it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  95% 448/470 [01:02<00:03,  7.13it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  96% 449/470 [01:02<00:02,  7.14it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  96% 450/470 [01:02<00:02,  7.15it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  96% 451/470 [01:02<00:02,  7.16it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  96% 452/470 [01:03<00:02,  7.17it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  96% 453/470 [01:03<00:02,  7.18it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  97% 454/470 [01:03<00:02,  7.20it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  97% 455/470 [01:03<00:02,  7.21it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  97% 456/470 [01:03<00:01,  7.22it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  97% 457/470 [01:03<00:01,  7.23it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  97% 458/470 [01:03<00:01,  7.24it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  98% 459/470 [01:03<00:01,  7.25it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  98% 460/470 [01:03<00:01,  7.26it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  98% 461/470 [01:03<00:01,  7.27it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  98% 462/470 [01:03<00:01,  7.28it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  99% 463/470 [01:03<00:00,  7.29it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  99% 464/470 [01:03<00:00,  7.31it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  99% 465/470 [01:03<00:00,  7.32it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  99% 466/470 [01:03<00:00,  7.33it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4:  99% 467/470 [01:03<00:00,  7.34it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4: 100% 468/470 [01:03<00:00,  7.35it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4: 100% 469/470 [01:03<00:00,  7.36it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.831]\n",
            "Epoch 4: 100% 470/470 [01:03<00:00,  7.38it/s, loss=0.418, v_num=3, train_accuracy=0.864, val_accuracy=0.829]\n",
            "Epoch 5:  83% 391/470 [01:01<00:12,  6.35it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 5:  83% 392/470 [01:02<00:12,  6.31it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  84% 393/470 [01:02<00:12,  6.32it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  84% 394/470 [01:02<00:12,  6.33it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  84% 395/470 [01:02<00:11,  6.34it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  84% 396/470 [01:02<00:11,  6.35it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  84% 397/470 [01:02<00:11,  6.36it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  85% 398/470 [01:02<00:11,  6.36it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  85% 399/470 [01:02<00:11,  6.37it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  85% 400/470 [01:02<00:10,  6.38it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  85% 401/470 [01:02<00:10,  6.39it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  86% 402/470 [01:02<00:10,  6.39it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  86% 403/470 [01:02<00:10,  6.40it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  86% 404/470 [01:03<00:10,  6.41it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  86% 405/470 [01:03<00:10,  6.42it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  86% 406/470 [01:03<00:09,  6.42it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  87% 407/470 [01:03<00:09,  6.43it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  87% 408/470 [01:03<00:09,  6.44it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  87% 409/470 [01:03<00:09,  6.45it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  87% 410/470 [01:03<00:09,  6.45it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  87% 411/470 [01:03<00:09,  6.46it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  88% 412/470 [01:03<00:08,  6.47it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  88% 413/470 [01:03<00:08,  6.48it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  88% 414/470 [01:03<00:08,  6.48it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  88% 415/470 [01:03<00:08,  6.49it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  89% 416/470 [01:04<00:08,  6.49it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  89% 417/470 [01:04<00:08,  6.50it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  89% 418/470 [01:04<00:07,  6.51it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  89% 419/470 [01:04<00:07,  6.52it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  89% 420/470 [01:04<00:07,  6.52it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  90% 421/470 [01:04<00:07,  6.53it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  90% 422/470 [01:04<00:07,  6.53it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  90% 423/470 [01:04<00:07,  6.55it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  90% 424/470 [01:04<00:07,  6.55it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  90% 425/470 [01:04<00:06,  6.56it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  91% 426/470 [01:04<00:06,  6.57it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  91% 427/470 [01:04<00:06,  6.58it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  91% 428/470 [01:04<00:06,  6.59it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  91% 429/470 [01:04<00:06,  6.60it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  91% 430/470 [01:05<00:06,  6.61it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  92% 431/470 [01:05<00:05,  6.63it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  92% 432/470 [01:05<00:05,  6.64it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  92% 433/470 [01:05<00:05,  6.65it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  92% 434/470 [01:05<00:05,  6.66it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  93% 435/470 [01:05<00:05,  6.67it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  93% 436/470 [01:05<00:05,  6.68it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  93% 437/470 [01:05<00:04,  6.69it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  93% 438/470 [01:05<00:04,  6.70it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  93% 439/470 [01:05<00:04,  6.71it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  94% 440/470 [01:05<00:04,  6.72it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  94% 441/470 [01:05<00:04,  6.73it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  94% 442/470 [01:05<00:04,  6.74it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  94% 443/470 [01:05<00:03,  6.75it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  94% 444/470 [01:05<00:03,  6.76it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  95% 445/470 [01:05<00:03,  6.77it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  95% 446/470 [01:05<00:03,  6.79it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  95% 447/470 [01:05<00:03,  6.80it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  95% 448/470 [01:05<00:03,  6.81it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  96% 449/470 [01:05<00:03,  6.82it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  96% 450/470 [01:05<00:02,  6.83it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  96% 451/470 [01:05<00:02,  6.84it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  96% 452/470 [01:05<00:02,  6.85it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  96% 453/470 [01:06<00:02,  6.86it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  97% 454/470 [01:06<00:02,  6.87it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  97% 455/470 [01:06<00:02,  6.88it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  97% 456/470 [01:06<00:02,  6.89it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  97% 457/470 [01:06<00:01,  6.90it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  97% 458/470 [01:06<00:01,  6.91it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  98% 459/470 [01:06<00:01,  6.92it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  98% 460/470 [01:06<00:01,  6.93it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  98% 461/470 [01:06<00:01,  6.94it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  98% 462/470 [01:06<00:01,  6.95it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  99% 463/470 [01:06<00:01,  6.96it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  99% 464/470 [01:06<00:00,  6.97it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  99% 465/470 [01:06<00:00,  6.98it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  99% 466/470 [01:06<00:00,  6.99it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5:  99% 467/470 [01:06<00:00,  7.01it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5: 100% 468/470 [01:06<00:00,  7.02it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5: 100% 469/470 [01:06<00:00,  7.03it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.829]\n",
            "Epoch 5: 100% 470/470 [01:06<00:00,  7.04it/s, loss=0.341, v_num=3, train_accuracy=0.878, val_accuracy=0.836]\n",
            "Epoch 6:  83% 391/470 [01:02<00:12,  6.22it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 6:  83% 392/470 [01:03<00:12,  6.18it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  84% 393/470 [01:03<00:12,  6.19it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  84% 394/470 [01:03<00:12,  6.20it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  84% 395/470 [01:03<00:12,  6.21it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  84% 396/470 [01:03<00:11,  6.22it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  84% 397/470 [01:03<00:11,  6.24it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  85% 398/470 [01:03<00:11,  6.25it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  85% 399/470 [01:03<00:11,  6.26it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  85% 400/470 [01:03<00:11,  6.26it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  85% 401/470 [01:03<00:10,  6.28it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  86% 402/470 [01:03<00:10,  6.29it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  86% 403/470 [01:04<00:10,  6.29it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  86% 404/470 [01:04<00:10,  6.30it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  86% 405/470 [01:04<00:10,  6.31it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  86% 406/470 [01:04<00:10,  6.32it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  87% 407/470 [01:04<00:09,  6.33it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  87% 408/470 [01:04<00:09,  6.33it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  87% 409/470 [01:04<00:09,  6.34it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  87% 410/470 [01:04<00:09,  6.35it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  87% 411/470 [01:04<00:09,  6.36it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  88% 412/470 [01:04<00:09,  6.38it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  88% 413/470 [01:04<00:08,  6.38it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  88% 414/470 [01:04<00:08,  6.39it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  88% 415/470 [01:04<00:08,  6.40it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  89% 416/470 [01:04<00:08,  6.41it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  89% 417/470 [01:05<00:08,  6.41it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  89% 418/470 [01:05<00:08,  6.42it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  89% 419/470 [01:05<00:07,  6.43it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  89% 420/470 [01:05<00:07,  6.44it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  90% 421/470 [01:05<00:07,  6.44it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  90% 422/470 [01:05<00:07,  6.45it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  90% 423/470 [01:05<00:07,  6.46it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  90% 424/470 [01:05<00:07,  6.47it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  90% 425/470 [01:05<00:06,  6.48it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  91% 426/470 [01:05<00:06,  6.49it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  91% 427/470 [01:05<00:06,  6.50it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  91% 428/470 [01:05<00:06,  6.51it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  91% 429/470 [01:05<00:06,  6.51it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  91% 430/470 [01:05<00:06,  6.52it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  92% 431/470 [01:05<00:05,  6.53it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  92% 432/470 [01:06<00:05,  6.54it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  92% 433/470 [01:06<00:05,  6.55it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  92% 434/470 [01:06<00:05,  6.56it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  93% 435/470 [01:06<00:05,  6.57it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  93% 436/470 [01:06<00:05,  6.58it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  93% 437/470 [01:06<00:05,  6.58it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  93% 438/470 [01:06<00:04,  6.59it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  93% 439/470 [01:06<00:04,  6.59it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  94% 440/470 [01:06<00:04,  6.60it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  94% 441/470 [01:06<00:04,  6.61it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  94% 442/470 [01:06<00:04,  6.62it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  94% 443/470 [01:06<00:04,  6.62it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  94% 444/470 [01:06<00:03,  6.63it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  95% 445/470 [01:07<00:03,  6.63it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  95% 446/470 [01:07<00:03,  6.64it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  95% 447/470 [01:07<00:03,  6.64it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  95% 448/470 [01:07<00:03,  6.65it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  96% 449/470 [01:07<00:03,  6.66it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  96% 450/470 [01:07<00:02,  6.67it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  96% 451/470 [01:07<00:02,  6.67it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  96% 452/470 [01:07<00:02,  6.68it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  96% 453/470 [01:07<00:02,  6.68it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  97% 454/470 [01:07<00:02,  6.69it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  97% 455/470 [01:07<00:02,  6.70it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  97% 456/470 [01:07<00:02,  6.71it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  97% 457/470 [01:08<00:01,  6.71it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  97% 458/470 [01:08<00:01,  6.72it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  98% 459/470 [01:08<00:01,  6.72it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  98% 460/470 [01:08<00:01,  6.73it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  98% 461/470 [01:08<00:01,  6.74it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  98% 462/470 [01:08<00:01,  6.75it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  99% 463/470 [01:08<00:01,  6.76it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  99% 464/470 [01:08<00:00,  6.77it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  99% 465/470 [01:08<00:00,  6.77it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  99% 466/470 [01:08<00:00,  6.78it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6:  99% 467/470 [01:08<00:00,  6.79it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6: 100% 468/470 [01:08<00:00,  6.79it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6: 100% 469/470 [01:08<00:00,  6.81it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.836]\n",
            "Epoch 6: 100% 470/470 [01:08<00:00,  6.82it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.835]\n",
            "Epoch 6: 100% 470/470 [01:08<00:00,  6.82it/s, loss=0.319, v_num=3, train_accuracy=0.891, val_accuracy=0.835]Epoch 00007: reducing learning rate of group 0 to 2.0000e-04.\n",
            "Epoch 7:  83% 391/470 [01:00<00:12,  6.51it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 7:  83% 392/470 [01:00<00:12,  6.49it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  84% 393/470 [01:00<00:11,  6.50it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  84% 394/470 [01:00<00:11,  6.52it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  84% 395/470 [01:00<00:11,  6.53it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  84% 396/470 [01:00<00:11,  6.54it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  84% 397/470 [01:00<00:11,  6.55it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  85% 398/470 [01:00<00:10,  6.56it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  85% 399/470 [01:00<00:10,  6.57it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  85% 400/470 [01:00<00:10,  6.58it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  85% 401/470 [01:00<00:10,  6.60it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  86% 402/470 [01:00<00:10,  6.61it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  86% 403/470 [01:00<00:10,  6.62it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  86% 404/470 [01:00<00:09,  6.63it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  86% 405/470 [01:00<00:09,  6.64it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  86% 406/470 [01:01<00:09,  6.65it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  87% 407/470 [01:01<00:09,  6.67it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  87% 408/470 [01:01<00:09,  6.68it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  87% 409/470 [01:01<00:09,  6.69it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  87% 410/470 [01:01<00:08,  6.70it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  87% 411/470 [01:01<00:08,  6.71it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  88% 412/470 [01:01<00:08,  6.72it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  88% 413/470 [01:01<00:08,  6.74it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  88% 414/470 [01:01<00:08,  6.75it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  88% 415/470 [01:01<00:08,  6.76it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  89% 416/470 [01:01<00:07,  6.77it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  89% 417/470 [01:01<00:07,  6.79it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  89% 418/470 [01:01<00:07,  6.79it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  89% 419/470 [01:01<00:07,  6.80it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  89% 420/470 [01:01<00:07,  6.81it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  90% 421/470 [01:01<00:07,  6.83it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  90% 422/470 [01:01<00:07,  6.83it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  90% 423/470 [01:01<00:06,  6.85it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  90% 424/470 [01:01<00:06,  6.86it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  90% 425/470 [01:01<00:06,  6.87it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  91% 426/470 [01:01<00:06,  6.88it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  91% 427/470 [01:01<00:06,  6.90it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  91% 428/470 [01:01<00:06,  6.91it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  91% 429/470 [01:01<00:05,  6.92it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  91% 430/470 [01:02<00:05,  6.93it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  92% 431/470 [01:02<00:05,  6.94it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  92% 432/470 [01:02<00:05,  6.95it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  92% 433/470 [01:02<00:05,  6.96it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  92% 434/470 [01:02<00:05,  6.97it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  93% 435/470 [01:02<00:05,  6.98it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  93% 436/470 [01:02<00:04,  7.00it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  93% 437/470 [01:02<00:04,  7.01it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  93% 438/470 [01:02<00:04,  7.02it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  93% 439/470 [01:02<00:04,  7.03it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  94% 440/470 [01:02<00:04,  7.04it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  94% 441/470 [01:02<00:04,  7.05it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  94% 442/470 [01:02<00:03,  7.06it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  94% 443/470 [01:02<00:03,  7.08it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  94% 444/470 [01:02<00:03,  7.09it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  95% 445/470 [01:02<00:03,  7.10it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  95% 446/470 [01:02<00:03,  7.11it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  95% 447/470 [01:02<00:03,  7.12it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  95% 448/470 [01:02<00:03,  7.13it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  96% 449/470 [01:02<00:02,  7.14it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  96% 450/470 [01:02<00:02,  7.15it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  96% 451/470 [01:02<00:02,  7.16it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  96% 452/470 [01:03<00:02,  7.17it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  96% 453/470 [01:03<00:02,  7.18it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  97% 454/470 [01:03<00:02,  7.19it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  97% 455/470 [01:03<00:02,  7.20it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  97% 456/470 [01:03<00:01,  7.21it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  97% 457/470 [01:03<00:01,  7.23it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  97% 458/470 [01:03<00:01,  7.24it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  98% 459/470 [01:03<00:01,  7.25it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  98% 460/470 [01:03<00:01,  7.26it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  98% 461/470 [01:03<00:01,  7.27it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  98% 462/470 [01:03<00:01,  7.28it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  99% 463/470 [01:03<00:00,  7.29it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  99% 464/470 [01:03<00:00,  7.30it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  99% 465/470 [01:03<00:00,  7.31it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  99% 466/470 [01:03<00:00,  7.32it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7:  99% 467/470 [01:03<00:00,  7.33it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7: 100% 468/470 [01:03<00:00,  7.34it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7: 100% 469/470 [01:03<00:00,  7.36it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.835]\n",
            "Epoch 7: 100% 470/470 [01:03<00:00,  7.37it/s, loss=0.225, v_num=3, train_accuracy=0.923, val_accuracy=0.861]\n",
            "Epoch 8:  83% 391/470 [01:04<00:12,  6.10it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 8:  83% 392/470 [01:04<00:12,  6.07it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  84% 393/470 [01:04<00:12,  6.08it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  84% 394/470 [01:04<00:12,  6.09it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  84% 395/470 [01:04<00:12,  6.10it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  84% 396/470 [01:04<00:12,  6.11it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  84% 397/470 [01:04<00:11,  6.12it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  85% 398/470 [01:04<00:11,  6.13it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  85% 399/470 [01:05<00:11,  6.13it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  85% 400/470 [01:05<00:11,  6.14it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  85% 401/470 [01:05<00:11,  6.15it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  86% 402/470 [01:05<00:11,  6.16it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  86% 403/470 [01:05<00:10,  6.16it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  86% 404/470 [01:05<00:10,  6.18it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  86% 405/470 [01:05<00:10,  6.19it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  86% 406/470 [01:05<00:10,  6.20it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  87% 407/470 [01:05<00:10,  6.21it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  87% 408/470 [01:05<00:09,  6.22it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  87% 409/470 [01:05<00:09,  6.23it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  87% 410/470 [01:05<00:09,  6.24it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  87% 411/470 [01:05<00:09,  6.25it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  88% 412/470 [01:05<00:09,  6.26it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  88% 413/470 [01:05<00:09,  6.27it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  88% 414/470 [01:05<00:08,  6.29it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  88% 415/470 [01:05<00:08,  6.30it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  89% 416/470 [01:05<00:08,  6.31it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  89% 417/470 [01:06<00:08,  6.32it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  89% 418/470 [01:06<00:08,  6.33it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  89% 419/470 [01:06<00:08,  6.34it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  89% 420/470 [01:06<00:07,  6.35it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  90% 421/470 [01:06<00:07,  6.36it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  90% 422/470 [01:06<00:07,  6.37it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  90% 423/470 [01:06<00:07,  6.38it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  90% 424/470 [01:06<00:07,  6.39it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  90% 425/470 [01:06<00:07,  6.40it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  91% 426/470 [01:06<00:06,  6.42it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  91% 427/470 [01:06<00:06,  6.42it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  91% 428/470 [01:06<00:06,  6.44it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  91% 429/470 [01:06<00:06,  6.45it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  91% 430/470 [01:06<00:06,  6.46it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  92% 431/470 [01:06<00:06,  6.47it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  92% 432/470 [01:06<00:05,  6.48it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  92% 433/470 [01:06<00:05,  6.49it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  92% 434/470 [01:06<00:05,  6.50it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  93% 435/470 [01:06<00:05,  6.51it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  93% 436/470 [01:06<00:05,  6.52it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  93% 437/470 [01:06<00:05,  6.53it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  93% 438/470 [01:06<00:04,  6.54it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  93% 439/470 [01:07<00:04,  6.55it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  94% 440/470 [01:07<00:04,  6.56it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  94% 441/470 [01:07<00:04,  6.57it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  94% 442/470 [01:07<00:04,  6.59it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  94% 443/470 [01:07<00:04,  6.59it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  94% 444/470 [01:07<00:03,  6.61it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  95% 445/470 [01:07<00:03,  6.62it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  95% 446/470 [01:07<00:03,  6.63it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  95% 447/470 [01:07<00:03,  6.64it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  95% 448/470 [01:07<00:03,  6.65it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  96% 449/470 [01:07<00:03,  6.66it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  96% 450/470 [01:07<00:02,  6.67it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  96% 451/470 [01:07<00:02,  6.68it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  96% 452/470 [01:07<00:02,  6.69it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  96% 453/470 [01:07<00:02,  6.70it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  97% 454/470 [01:07<00:02,  6.71it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  97% 455/470 [01:07<00:02,  6.72it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  97% 456/470 [01:07<00:02,  6.73it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  97% 457/470 [01:07<00:01,  6.74it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  97% 458/470 [01:07<00:01,  6.75it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  98% 459/470 [01:07<00:01,  6.76it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  98% 460/470 [01:07<00:01,  6.77it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  98% 461/470 [01:08<00:01,  6.78it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  98% 462/470 [01:08<00:01,  6.79it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  99% 463/470 [01:08<00:01,  6.80it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  99% 464/470 [01:08<00:00,  6.81it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  99% 465/470 [01:08<00:00,  6.82it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  99% 466/470 [01:08<00:00,  6.83it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8:  99% 467/470 [01:08<00:00,  6.84it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8: 100% 468/470 [01:08<00:00,  6.85it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8: 100% 469/470 [01:08<00:00,  6.86it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.861]\n",
            "Epoch 8: 100% 470/470 [01:08<00:00,  6.88it/s, loss=0.197, v_num=3, train_accuracy=0.937, val_accuracy=0.858]\n",
            "Epoch 9:  83% 391/470 [01:03<00:12,  6.19it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9:  83% 392/470 [01:03<00:12,  6.16it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  84% 393/470 [01:03<00:12,  6.17it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  84% 394/470 [01:03<00:12,  6.18it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  84% 395/470 [01:03<00:12,  6.19it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  84% 396/470 [01:03<00:11,  6.20it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  84% 397/470 [01:03<00:11,  6.21it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  85% 398/470 [01:04<00:11,  6.21it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  85% 399/470 [01:04<00:11,  6.23it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  85% 400/470 [01:04<00:11,  6.23it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  85% 401/470 [01:04<00:11,  6.24it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  86% 402/470 [01:04<00:10,  6.25it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  86% 403/470 [01:04<00:10,  6.26it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  86% 404/470 [01:04<00:10,  6.26it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  86% 405/470 [01:04<00:10,  6.27it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  86% 406/470 [01:04<00:10,  6.28it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  87% 407/470 [01:04<00:10,  6.29it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  87% 408/470 [01:04<00:09,  6.30it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  87% 409/470 [01:04<00:09,  6.31it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  87% 410/470 [01:04<00:09,  6.31it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  87% 411/470 [01:04<00:09,  6.32it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  88% 412/470 [01:05<00:09,  6.33it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  88% 413/470 [01:05<00:08,  6.34it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  88% 414/470 [01:05<00:08,  6.35it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  88% 415/470 [01:05<00:08,  6.36it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  89% 416/470 [01:05<00:08,  6.36it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  89% 417/470 [01:05<00:08,  6.37it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  89% 418/470 [01:05<00:08,  6.38it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  89% 419/470 [01:05<00:07,  6.39it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  89% 420/470 [01:05<00:07,  6.40it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  90% 421/470 [01:05<00:07,  6.41it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  90% 422/470 [01:05<00:07,  6.41it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  90% 423/470 [01:05<00:07,  6.42it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  90% 424/470 [01:05<00:07,  6.42it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  90% 425/470 [01:06<00:06,  6.43it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  91% 426/470 [01:06<00:06,  6.44it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  91% 427/470 [01:06<00:06,  6.45it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  91% 428/470 [01:06<00:06,  6.45it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  91% 429/470 [01:06<00:06,  6.46it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  91% 430/470 [01:06<00:06,  6.46it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  92% 431/470 [01:06<00:06,  6.47it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  92% 432/470 [01:06<00:05,  6.48it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  92% 433/470 [01:06<00:05,  6.49it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  92% 434/470 [01:06<00:05,  6.49it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  93% 435/470 [01:06<00:05,  6.50it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  93% 436/470 [01:07<00:05,  6.51it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  93% 437/470 [01:07<00:05,  6.52it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  93% 438/470 [01:07<00:04,  6.52it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  93% 439/470 [01:07<00:04,  6.53it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  94% 440/470 [01:07<00:04,  6.54it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  94% 441/470 [01:07<00:04,  6.55it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  94% 442/470 [01:07<00:04,  6.55it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  94% 443/470 [01:07<00:04,  6.56it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  94% 444/470 [01:07<00:03,  6.57it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  95% 445/470 [01:07<00:03,  6.58it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  95% 446/470 [01:07<00:03,  6.58it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  95% 447/470 [01:07<00:03,  6.59it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  95% 448/470 [01:07<00:03,  6.60it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  96% 449/470 [01:07<00:03,  6.61it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  96% 450/470 [01:08<00:03,  6.62it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  96% 451/470 [01:08<00:02,  6.63it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  96% 452/470 [01:08<00:02,  6.63it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  96% 453/470 [01:08<00:02,  6.64it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  97% 454/470 [01:08<00:02,  6.64it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  97% 455/470 [01:08<00:02,  6.65it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  97% 456/470 [01:08<00:02,  6.66it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  97% 457/470 [01:08<00:01,  6.67it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  97% 458/470 [01:08<00:01,  6.68it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  98% 459/470 [01:08<00:01,  6.68it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  98% 460/470 [01:08<00:01,  6.69it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  98% 461/470 [01:08<00:01,  6.70it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  98% 462/470 [01:08<00:01,  6.71it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  99% 463/470 [01:08<00:01,  6.71it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  99% 464/470 [01:09<00:00,  6.72it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  99% 465/470 [01:09<00:00,  6.73it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  99% 466/470 [01:09<00:00,  6.74it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9:  99% 467/470 [01:09<00:00,  6.74it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9: 100% 468/470 [01:09<00:00,  6.75it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9: 100% 469/470 [01:09<00:00,  6.76it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.858]\n",
            "Epoch 9: 100% 470/470 [01:09<00:00,  6.77it/s, loss=0.194, v_num=3, train_accuracy=0.943, val_accuracy=0.860]\n",
            "Epoch 10:  83% 391/470 [00:58<00:11,  6.68it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 10:  83% 392/470 [00:58<00:11,  6.66it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  84% 393/470 [00:58<00:11,  6.67it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  84% 394/470 [00:58<00:11,  6.68it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  84% 395/470 [00:58<00:11,  6.70it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  84% 396/470 [00:59<00:11,  6.71it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  84% 397/470 [00:59<00:10,  6.72it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  85% 398/470 [00:59<00:10,  6.73it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  85% 399/470 [00:59<00:10,  6.75it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  85% 400/470 [00:59<00:10,  6.75it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  85% 401/470 [00:59<00:10,  6.77it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  86% 402/470 [00:59<00:10,  6.78it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  86% 403/470 [00:59<00:09,  6.79it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  86% 404/470 [00:59<00:09,  6.80it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  86% 405/470 [00:59<00:09,  6.82it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  86% 406/470 [00:59<00:09,  6.83it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  87% 407/470 [00:59<00:09,  6.84it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  87% 408/470 [00:59<00:09,  6.85it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  87% 409/470 [00:59<00:08,  6.86it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  87% 410/470 [00:59<00:08,  6.88it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  87% 411/470 [00:59<00:08,  6.89it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  88% 412/470 [00:59<00:08,  6.90it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  88% 413/470 [00:59<00:08,  6.91it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  88% 414/470 [00:59<00:08,  6.92it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  88% 415/470 [00:59<00:07,  6.93it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  89% 416/470 [00:59<00:07,  6.94it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  89% 417/470 [00:59<00:07,  6.96it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  89% 418/470 [01:00<00:07,  6.97it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  89% 419/470 [01:00<00:07,  6.98it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  89% 420/470 [01:00<00:07,  6.99it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  90% 421/470 [01:00<00:06,  7.00it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  90% 422/470 [01:00<00:06,  7.01it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  90% 423/470 [01:00<00:06,  7.03it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  90% 424/470 [01:00<00:06,  7.04it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  90% 425/470 [01:00<00:06,  7.05it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  91% 426/470 [01:00<00:06,  7.06it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  91% 427/470 [01:00<00:06,  7.07it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  91% 428/470 [01:00<00:05,  7.08it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  91% 429/470 [01:00<00:05,  7.10it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  91% 430/470 [01:00<00:05,  7.10it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  92% 431/470 [01:00<00:05,  7.12it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  92% 432/470 [01:00<00:05,  7.13it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  92% 433/470 [01:00<00:05,  7.14it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  92% 434/470 [01:00<00:05,  7.15it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  93% 435/470 [01:00<00:04,  7.16it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  93% 436/470 [01:00<00:04,  7.17it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  93% 437/470 [01:00<00:04,  7.19it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  93% 438/470 [01:00<00:04,  7.19it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  93% 439/470 [01:00<00:04,  7.21it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  94% 440/470 [01:00<00:04,  7.22it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  94% 441/470 [01:01<00:04,  7.23it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  94% 442/470 [01:01<00:03,  7.24it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  94% 443/470 [01:01<00:03,  7.25it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  94% 444/470 [01:01<00:03,  7.26it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  95% 445/470 [01:01<00:03,  7.27it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  95% 446/470 [01:01<00:03,  7.28it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  95% 447/470 [01:01<00:03,  7.29it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  95% 448/470 [01:01<00:03,  7.31it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  96% 449/470 [01:01<00:02,  7.32it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  96% 450/470 [01:01<00:02,  7.33it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  96% 451/470 [01:01<00:02,  7.34it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  96% 452/470 [01:01<00:02,  7.35it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  96% 453/470 [01:01<00:02,  7.37it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  97% 454/470 [01:01<00:02,  7.37it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  97% 455/470 [01:01<00:02,  7.39it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  97% 456/470 [01:01<00:01,  7.40it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  97% 457/470 [01:01<00:01,  7.41it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  97% 458/470 [01:01<00:01,  7.42it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  98% 459/470 [01:01<00:01,  7.43it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  98% 460/470 [01:01<00:01,  7.44it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  98% 461/470 [01:01<00:01,  7.45it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  98% 462/470 [01:01<00:01,  7.46it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  99% 463/470 [01:01<00:00,  7.47it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  99% 464/470 [01:01<00:00,  7.48it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  99% 465/470 [01:02<00:00,  7.50it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  99% 466/470 [01:02<00:00,  7.51it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10:  99% 467/470 [01:02<00:00,  7.52it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10: 100% 468/470 [01:02<00:00,  7.53it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10: 100% 469/470 [01:02<00:00,  7.54it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.860]\n",
            "Epoch 10: 100% 470/470 [01:02<00:00,  7.55it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.853]\n",
            "Epoch 10: 100% 470/470 [01:02<00:00,  7.55it/s, loss=0.147, v_num=3, train_accuracy=0.949, val_accuracy=0.853]Epoch 00011: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch 11:  83% 391/470 [01:02<00:12,  6.22it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 11:  83% 392/470 [01:03<00:12,  6.19it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  84% 393/470 [01:03<00:12,  6.20it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  84% 394/470 [01:03<00:12,  6.20it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  84% 395/470 [01:03<00:12,  6.21it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  84% 396/470 [01:03<00:11,  6.22it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  84% 397/470 [01:03<00:11,  6.23it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  85% 398/470 [01:03<00:11,  6.24it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  85% 399/470 [01:03<00:11,  6.25it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  85% 400/470 [01:03<00:11,  6.25it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  85% 401/470 [01:04<00:11,  6.27it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  86% 402/470 [01:04<00:10,  6.27it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  86% 403/470 [01:04<00:10,  6.28it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  86% 404/470 [01:04<00:10,  6.28it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  86% 405/470 [01:04<00:10,  6.29it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  86% 406/470 [01:04<00:10,  6.30it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  87% 407/470 [01:04<00:09,  6.31it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  87% 408/470 [01:04<00:09,  6.32it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  87% 409/470 [01:04<00:09,  6.33it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  87% 410/470 [01:04<00:09,  6.34it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  87% 411/470 [01:04<00:09,  6.35it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  88% 412/470 [01:04<00:09,  6.36it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  88% 413/470 [01:04<00:08,  6.37it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  88% 414/470 [01:04<00:08,  6.38it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  88% 415/470 [01:04<00:08,  6.40it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  89% 416/470 [01:04<00:08,  6.41it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  89% 417/470 [01:04<00:08,  6.42it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  89% 418/470 [01:05<00:08,  6.43it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  89% 419/470 [01:05<00:07,  6.44it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  89% 420/470 [01:05<00:07,  6.45it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  90% 421/470 [01:05<00:07,  6.46it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  90% 422/470 [01:05<00:07,  6.47it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  90% 423/470 [01:05<00:07,  6.48it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  90% 424/470 [01:05<00:07,  6.49it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  90% 425/470 [01:05<00:06,  6.50it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  91% 426/470 [01:05<00:06,  6.52it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  91% 427/470 [01:05<00:06,  6.52it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  91% 428/470 [01:05<00:06,  6.54it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  91% 429/470 [01:05<00:06,  6.55it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  91% 430/470 [01:05<00:06,  6.56it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  92% 431/470 [01:05<00:05,  6.57it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  92% 432/470 [01:05<00:05,  6.58it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  92% 433/470 [01:05<00:05,  6.59it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  92% 434/470 [01:05<00:05,  6.60it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  93% 435/470 [01:05<00:05,  6.61it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  93% 436/470 [01:05<00:05,  6.62it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  93% 437/470 [01:05<00:04,  6.63it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  93% 438/470 [01:05<00:04,  6.64it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  93% 439/470 [01:05<00:04,  6.65it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  94% 440/470 [01:06<00:04,  6.66it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  94% 441/470 [01:06<00:04,  6.68it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  94% 442/470 [01:06<00:04,  6.69it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  94% 443/470 [01:06<00:04,  6.70it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  94% 444/470 [01:06<00:03,  6.71it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  95% 445/470 [01:06<00:03,  6.72it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  95% 446/470 [01:06<00:03,  6.73it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  95% 447/470 [01:06<00:03,  6.74it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  95% 448/470 [01:06<00:03,  6.75it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  96% 449/470 [01:06<00:03,  6.76it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  96% 450/470 [01:06<00:02,  6.77it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  96% 451/470 [01:06<00:02,  6.78it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  96% 452/470 [01:06<00:02,  6.79it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  96% 453/470 [01:06<00:02,  6.80it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  97% 454/470 [01:06<00:02,  6.81it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  97% 455/470 [01:06<00:02,  6.82it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  97% 456/470 [01:06<00:02,  6.83it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  97% 457/470 [01:06<00:01,  6.84it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  97% 458/470 [01:06<00:01,  6.85it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  98% 459/470 [01:06<00:01,  6.86it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  98% 460/470 [01:06<00:01,  6.87it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  98% 461/470 [01:06<00:01,  6.88it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  98% 462/470 [01:06<00:01,  6.90it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  99% 463/470 [01:07<00:01,  6.90it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  99% 464/470 [01:07<00:00,  6.92it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  99% 465/470 [01:07<00:00,  6.92it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  99% 466/470 [01:07<00:00,  6.94it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11:  99% 467/470 [01:07<00:00,  6.94it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11: 100% 468/470 [01:07<00:00,  6.96it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11: 100% 469/470 [01:07<00:00,  6.97it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.853]\n",
            "Epoch 11: 100% 470/470 [01:07<00:00,  6.98it/s, loss=0.112, v_num=3, train_accuracy=0.962, val_accuracy=0.864]\n",
            "Epoch 12:  83% 391/470 [00:59<00:12,  6.56it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 12:  83% 392/470 [01:00<00:11,  6.52it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  84% 393/470 [01:00<00:11,  6.53it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  84% 394/470 [01:00<00:11,  6.54it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  84% 395/470 [01:00<00:11,  6.55it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  84% 396/470 [01:00<00:11,  6.56it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  84% 397/470 [01:00<00:11,  6.56it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  85% 398/470 [01:00<00:10,  6.57it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  85% 399/470 [01:00<00:10,  6.58it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  85% 400/470 [01:00<00:10,  6.59it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  85% 401/470 [01:00<00:10,  6.60it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  86% 402/470 [01:00<00:10,  6.61it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  86% 403/470 [01:00<00:10,  6.62it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  86% 404/470 [01:00<00:09,  6.63it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  86% 405/470 [01:01<00:09,  6.64it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  86% 406/470 [01:01<00:09,  6.65it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  87% 407/470 [01:01<00:09,  6.66it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  87% 408/470 [01:01<00:09,  6.67it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  87% 409/470 [01:01<00:09,  6.67it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  87% 410/470 [01:01<00:08,  6.68it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  87% 411/470 [01:01<00:08,  6.69it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  88% 412/470 [01:01<00:08,  6.69it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  88% 413/470 [01:01<00:08,  6.70it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  88% 414/470 [01:01<00:08,  6.71it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  88% 415/470 [01:01<00:08,  6.72it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  89% 416/470 [01:01<00:08,  6.73it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  89% 417/470 [01:01<00:07,  6.73it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  89% 418/470 [01:02<00:07,  6.74it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  89% 419/470 [01:02<00:07,  6.74it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  89% 420/470 [01:02<00:07,  6.75it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  90% 421/470 [01:02<00:07,  6.75it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  90% 422/470 [01:02<00:07,  6.77it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  90% 423/470 [01:02<00:06,  6.77it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  90% 424/470 [01:02<00:06,  6.78it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  90% 425/470 [01:02<00:06,  6.79it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  91% 426/470 [01:02<00:06,  6.80it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  91% 427/470 [01:02<00:06,  6.81it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  91% 428/470 [01:02<00:06,  6.82it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  91% 429/470 [01:02<00:06,  6.82it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  91% 430/470 [01:02<00:05,  6.83it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  92% 431/470 [01:03<00:05,  6.84it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  92% 432/470 [01:03<00:05,  6.85it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  92% 433/470 [01:03<00:05,  6.85it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  92% 434/470 [01:03<00:05,  6.87it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  93% 435/470 [01:03<00:05,  6.87it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  93% 436/470 [01:03<00:04,  6.88it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  93% 437/470 [01:03<00:04,  6.88it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  93% 438/470 [01:03<00:04,  6.89it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  93% 439/470 [01:03<00:04,  6.89it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  94% 440/470 [01:03<00:04,  6.90it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  94% 441/470 [01:03<00:04,  6.91it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  94% 442/470 [01:03<00:04,  6.92it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  94% 443/470 [01:03<00:03,  6.92it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  94% 444/470 [01:04<00:03,  6.93it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  95% 445/470 [01:04<00:03,  6.94it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  95% 446/470 [01:04<00:03,  6.95it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  95% 447/470 [01:04<00:03,  6.95it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  95% 448/470 [01:04<00:03,  6.97it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  96% 449/470 [01:04<00:03,  6.97it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  96% 450/470 [01:04<00:02,  6.99it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  96% 451/470 [01:04<00:02,  6.99it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  96% 452/470 [01:04<00:02,  7.00it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  96% 453/470 [01:04<00:02,  7.01it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  97% 454/470 [01:04<00:02,  7.02it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  97% 455/470 [01:04<00:02,  7.02it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  97% 456/470 [01:04<00:01,  7.03it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  97% 457/470 [01:04<00:01,  7.03it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  97% 458/470 [01:05<00:01,  7.04it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  98% 459/470 [01:05<00:01,  7.04it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  98% 460/470 [01:05<00:01,  7.05it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  98% 461/470 [01:05<00:01,  7.06it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  98% 462/470 [01:05<00:01,  7.07it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  99% 463/470 [01:05<00:00,  7.07it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  99% 464/470 [01:05<00:00,  7.08it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  99% 465/470 [01:05<00:00,  7.08it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  99% 466/470 [01:05<00:00,  7.09it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12:  99% 467/470 [01:05<00:00,  7.10it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12: 100% 468/470 [01:05<00:00,  7.11it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12: 100% 469/470 [01:05<00:00,  7.12it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.864]\n",
            "Epoch 12: 100% 470/470 [01:05<00:00,  7.13it/s, loss=0.0947, v_num=3, train_accuracy=0.969, val_accuracy=0.862]\n",
            "Epoch 13:  83% 391/470 [01:03<00:12,  6.17it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862] \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 13:  83% 392/470 [01:03<00:12,  6.15it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  84% 393/470 [01:03<00:12,  6.16it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  84% 394/470 [01:03<00:12,  6.18it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  84% 395/470 [01:03<00:12,  6.19it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  84% 396/470 [01:03<00:11,  6.20it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  84% 397/470 [01:03<00:11,  6.21it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  85% 398/470 [01:03<00:11,  6.22it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  85% 399/470 [01:03<00:11,  6.24it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  85% 400/470 [01:04<00:11,  6.25it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  85% 401/470 [01:04<00:11,  6.26it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  86% 402/470 [01:04<00:10,  6.26it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  86% 403/470 [01:04<00:10,  6.27it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  86% 404/470 [01:04<00:10,  6.28it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  86% 405/470 [01:04<00:10,  6.29it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  86% 406/470 [01:04<00:10,  6.30it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  87% 407/470 [01:04<00:09,  6.31it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  87% 408/470 [01:04<00:09,  6.31it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  87% 409/470 [01:04<00:09,  6.32it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  87% 410/470 [01:04<00:09,  6.33it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  87% 411/470 [01:04<00:09,  6.34it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  88% 412/470 [01:04<00:09,  6.35it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  88% 413/470 [01:04<00:08,  6.36it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  88% 414/470 [01:05<00:08,  6.36it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  88% 415/470 [01:05<00:08,  6.38it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  89% 416/470 [01:05<00:08,  6.38it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  89% 417/470 [01:05<00:08,  6.39it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  89% 418/470 [01:05<00:08,  6.40it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  89% 419/470 [01:05<00:07,  6.42it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  89% 420/470 [01:05<00:07,  6.42it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  90% 421/470 [01:05<00:07,  6.43it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  90% 422/470 [01:05<00:07,  6.44it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  90% 423/470 [01:05<00:07,  6.45it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  90% 424/470 [01:05<00:07,  6.46it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  90% 425/470 [01:05<00:06,  6.47it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  91% 426/470 [01:05<00:06,  6.48it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  91% 427/470 [01:05<00:06,  6.49it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  91% 428/470 [01:05<00:06,  6.49it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  91% 429/470 [01:05<00:06,  6.50it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  91% 430/470 [01:06<00:06,  6.50it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  92% 431/470 [01:06<00:05,  6.51it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  92% 432/470 [01:06<00:05,  6.52it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  92% 433/470 [01:06<00:05,  6.53it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  92% 434/470 [01:06<00:05,  6.54it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  93% 435/470 [01:06<00:05,  6.55it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  93% 436/470 [01:06<00:05,  6.55it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  93% 437/470 [01:06<00:05,  6.57it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  93% 438/470 [01:06<00:04,  6.57it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  93% 439/470 [01:06<00:04,  6.58it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  94% 440/470 [01:06<00:04,  6.58it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  94% 441/470 [01:06<00:04,  6.59it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  94% 442/470 [01:06<00:04,  6.60it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  94% 443/470 [01:07<00:04,  6.61it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  94% 444/470 [01:07<00:03,  6.61it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  95% 445/470 [01:07<00:03,  6.62it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  95% 446/470 [01:07<00:03,  6.62it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  95% 447/470 [01:07<00:03,  6.63it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  95% 448/470 [01:07<00:03,  6.64it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  96% 449/470 [01:07<00:03,  6.65it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  96% 450/470 [01:07<00:03,  6.66it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  96% 451/470 [01:07<00:02,  6.66it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  96% 452/470 [01:07<00:02,  6.67it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  96% 453/470 [01:07<00:02,  6.68it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  97% 454/470 [01:07<00:02,  6.69it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  97% 455/470 [01:07<00:02,  6.70it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  97% 456/470 [01:07<00:02,  6.71it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  97% 457/470 [01:08<00:01,  6.72it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  97% 458/470 [01:08<00:01,  6.72it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  98% 459/470 [01:08<00:01,  6.73it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  98% 460/470 [01:08<00:01,  6.74it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  98% 461/470 [01:08<00:01,  6.75it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  98% 462/470 [01:08<00:01,  6.75it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  99% 463/470 [01:08<00:01,  6.76it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  99% 464/470 [01:08<00:00,  6.77it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  99% 465/470 [01:08<00:00,  6.78it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  99% 466/470 [01:08<00:00,  6.78it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13:  99% 467/470 [01:08<00:00,  6.79it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13: 100% 468/470 [01:08<00:00,  6.80it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13: 100% 469/470 [01:08<00:00,  6.81it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.862]\n",
            "Epoch 13: 100% 470/470 [01:08<00:00,  6.82it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.864]\n",
            "Epoch 13: 100% 470/470 [01:08<00:00,  6.82it/s, loss=0.086, v_num=3, train_accuracy=0.973, val_accuracy=0.864]Epoch 00014: reducing learning rate of group 0 to 5.0000e-05.\n",
            "Epoch 14:  83% 391/470 [01:02<00:12,  6.29it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 14:  83% 392/470 [01:02<00:12,  6.28it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  84% 393/470 [01:02<00:12,  6.29it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  84% 394/470 [01:02<00:12,  6.30it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  84% 395/470 [01:02<00:11,  6.32it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  84% 396/470 [01:02<00:11,  6.33it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  84% 397/470 [01:02<00:11,  6.34it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  85% 398/470 [01:02<00:11,  6.35it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  85% 399/470 [01:02<00:11,  6.36it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  85% 400/470 [01:02<00:10,  6.37it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  85% 401/470 [01:02<00:10,  6.39it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  86% 402/470 [01:02<00:10,  6.40it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  86% 403/470 [01:02<00:10,  6.41it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  86% 404/470 [01:02<00:10,  6.42it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  86% 405/470 [01:02<00:10,  6.43it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  86% 406/470 [01:03<00:09,  6.44it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  87% 407/470 [01:03<00:09,  6.45it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  87% 408/470 [01:03<00:09,  6.46it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  87% 409/470 [01:03<00:09,  6.48it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  87% 410/470 [01:03<00:09,  6.49it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  87% 411/470 [01:03<00:09,  6.50it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  88% 412/470 [01:03<00:08,  6.51it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  88% 413/470 [01:03<00:08,  6.52it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  88% 414/470 [01:03<00:08,  6.53it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  88% 415/470 [01:03<00:08,  6.54it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  89% 416/470 [01:03<00:08,  6.55it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  89% 417/470 [01:03<00:08,  6.56it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  89% 418/470 [01:03<00:07,  6.58it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  89% 419/470 [01:03<00:07,  6.59it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  89% 420/470 [01:03<00:07,  6.60it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  90% 421/470 [01:03<00:07,  6.61it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  90% 422/470 [01:03<00:07,  6.63it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  90% 423/470 [01:03<00:07,  6.63it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  90% 424/470 [01:03<00:06,  6.65it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  90% 425/470 [01:03<00:06,  6.65it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  91% 426/470 [01:03<00:06,  6.67it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  91% 427/470 [01:03<00:06,  6.68it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  91% 428/470 [01:03<00:06,  6.69it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  91% 429/470 [01:04<00:06,  6.70it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  91% 430/470 [01:04<00:05,  6.71it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  92% 431/470 [01:04<00:05,  6.72it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  92% 432/470 [01:04<00:05,  6.73it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  92% 433/470 [01:04<00:05,  6.74it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  92% 434/470 [01:04<00:05,  6.75it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  93% 435/470 [01:04<00:05,  6.76it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  93% 436/470 [01:04<00:05,  6.77it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  93% 437/470 [01:04<00:04,  6.79it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  93% 438/470 [01:04<00:04,  6.79it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  93% 439/470 [01:04<00:04,  6.80it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  94% 440/470 [01:04<00:04,  6.82it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  94% 441/470 [01:04<00:04,  6.83it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  94% 442/470 [01:04<00:04,  6.84it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  94% 443/470 [01:04<00:03,  6.85it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  94% 444/470 [01:04<00:03,  6.86it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  95% 445/470 [01:04<00:03,  6.87it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  95% 446/470 [01:04<00:03,  6.88it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  95% 447/470 [01:04<00:03,  6.89it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  95% 448/470 [01:04<00:03,  6.90it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  96% 449/470 [01:04<00:03,  6.91it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  96% 450/470 [01:04<00:02,  6.93it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  96% 451/470 [01:05<00:02,  6.94it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  96% 452/470 [01:05<00:02,  6.95it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  96% 453/470 [01:05<00:02,  6.96it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  97% 454/470 [01:05<00:02,  6.97it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  97% 455/470 [01:05<00:02,  6.98it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  97% 456/470 [01:05<00:02,  6.99it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  97% 457/470 [01:05<00:01,  7.00it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  97% 458/470 [01:05<00:01,  7.01it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  98% 459/470 [01:05<00:01,  7.02it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  98% 460/470 [01:05<00:01,  7.03it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  98% 461/470 [01:05<00:01,  7.04it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  98% 462/470 [01:05<00:01,  7.05it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  99% 463/470 [01:05<00:00,  7.06it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  99% 464/470 [01:05<00:00,  7.07it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  99% 465/470 [01:05<00:00,  7.08it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  99% 466/470 [01:05<00:00,  7.09it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14:  99% 467/470 [01:05<00:00,  7.10it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14: 100% 468/470 [01:05<00:00,  7.11it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14: 100% 469/470 [01:05<00:00,  7.13it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.864]\n",
            "Epoch 14: 100% 470/470 [01:05<00:00,  7.14it/s, loss=0.0615, v_num=3, train_accuracy=0.979, val_accuracy=0.869]\n",
            "Epoch 15:  83% 391/470 [01:02<00:12,  6.30it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 15:  83% 392/470 [01:02<00:12,  6.28it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  84% 393/470 [01:02<00:12,  6.29it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  84% 394/470 [01:02<00:12,  6.30it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  84% 395/470 [01:02<00:11,  6.30it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  84% 396/470 [01:02<00:11,  6.31it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  84% 397/470 [01:02<00:11,  6.32it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  85% 398/470 [01:02<00:11,  6.33it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  85% 399/470 [01:02<00:11,  6.34it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  85% 400/470 [01:03<00:11,  6.34it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  85% 401/470 [01:03<00:10,  6.35it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  86% 402/470 [01:03<00:10,  6.36it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  86% 403/470 [01:03<00:10,  6.37it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  86% 404/470 [01:03<00:10,  6.37it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  86% 405/470 [01:03<00:10,  6.38it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  86% 406/470 [01:03<00:10,  6.39it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  87% 407/470 [01:03<00:09,  6.40it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  87% 408/470 [01:03<00:09,  6.41it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  87% 409/470 [01:03<00:09,  6.42it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  87% 410/470 [01:03<00:09,  6.42it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  87% 411/470 [01:03<00:09,  6.44it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  88% 412/470 [01:03<00:09,  6.44it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  88% 413/470 [01:04<00:08,  6.45it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  88% 414/470 [01:04<00:08,  6.45it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  88% 415/470 [01:04<00:08,  6.47it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  89% 416/470 [01:04<00:08,  6.47it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  89% 417/470 [01:04<00:08,  6.48it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  89% 418/470 [01:04<00:08,  6.49it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  89% 419/470 [01:04<00:07,  6.50it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  89% 420/470 [01:04<00:07,  6.50it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  90% 421/470 [01:04<00:07,  6.51it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  90% 422/470 [01:04<00:07,  6.52it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  90% 423/470 [01:04<00:07,  6.53it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  90% 424/470 [01:04<00:07,  6.54it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  90% 425/470 [01:04<00:06,  6.54it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  91% 426/470 [01:05<00:06,  6.55it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  91% 427/470 [01:05<00:06,  6.55it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  91% 428/470 [01:05<00:06,  6.56it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  91% 429/470 [01:05<00:06,  6.56it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  91% 430/470 [01:05<00:06,  6.57it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  92% 431/470 [01:05<00:05,  6.58it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  92% 432/470 [01:05<00:05,  6.59it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  92% 433/470 [01:05<00:05,  6.60it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  92% 434/470 [01:05<00:05,  6.61it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  93% 435/470 [01:05<00:05,  6.61it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  93% 436/470 [01:05<00:05,  6.62it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  93% 437/470 [01:06<00:04,  6.62it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  93% 438/470 [01:06<00:04,  6.63it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  93% 439/470 [01:06<00:04,  6.64it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  94% 440/470 [01:06<00:04,  6.65it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  94% 441/470 [01:06<00:04,  6.65it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  94% 442/470 [01:06<00:04,  6.66it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  94% 443/470 [01:06<00:04,  6.67it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  94% 444/470 [01:06<00:03,  6.68it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  95% 445/470 [01:06<00:03,  6.68it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  95% 446/470 [01:06<00:03,  6.69it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  95% 447/470 [01:06<00:03,  6.70it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  95% 448/470 [01:06<00:03,  6.70it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  96% 449/470 [01:06<00:03,  6.71it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  96% 450/470 [01:06<00:02,  6.72it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  96% 451/470 [01:07<00:02,  6.73it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  96% 452/470 [01:07<00:02,  6.73it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  96% 453/470 [01:07<00:02,  6.74it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  97% 454/470 [01:07<00:02,  6.74it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  97% 455/470 [01:07<00:02,  6.75it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  97% 456/470 [01:07<00:02,  6.76it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  97% 457/470 [01:07<00:01,  6.76it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  97% 458/470 [01:07<00:01,  6.77it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  98% 459/470 [01:07<00:01,  6.78it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  98% 460/470 [01:07<00:01,  6.78it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  98% 461/470 [01:07<00:01,  6.80it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  98% 462/470 [01:07<00:01,  6.80it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  99% 463/470 [01:07<00:01,  6.81it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  99% 464/470 [01:08<00:00,  6.81it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  99% 465/470 [01:08<00:00,  6.82it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  99% 466/470 [01:08<00:00,  6.82it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15:  99% 467/470 [01:08<00:00,  6.84it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15: 100% 468/470 [01:08<00:00,  6.84it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15: 100% 469/470 [01:08<00:00,  6.86it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.869]\n",
            "Epoch 15: 100% 470/470 [01:08<00:00,  6.87it/s, loss=0.0588, v_num=3, train_accuracy=0.982, val_accuracy=0.868]\n",
            "Epoch 16:  83% 391/470 [01:02<00:12,  6.21it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 16:  83% 392/470 [01:03<00:12,  6.18it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  84% 393/470 [01:03<00:12,  6.18it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  84% 394/470 [01:03<00:12,  6.19it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  84% 395/470 [01:03<00:12,  6.19it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  84% 396/470 [01:03<00:11,  6.21it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  84% 397/470 [01:03<00:11,  6.21it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  85% 398/470 [01:03<00:11,  6.23it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  85% 399/470 [01:04<00:11,  6.23it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  85% 400/470 [01:04<00:11,  6.24it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  85% 401/470 [01:04<00:11,  6.25it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  86% 402/470 [01:04<00:10,  6.26it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  86% 403/470 [01:04<00:10,  6.26it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  86% 404/470 [01:04<00:10,  6.27it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  86% 405/470 [01:04<00:10,  6.28it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  86% 406/470 [01:04<00:10,  6.29it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  87% 407/470 [01:04<00:10,  6.29it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  87% 408/470 [01:04<00:09,  6.30it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  87% 409/470 [01:04<00:09,  6.31it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  87% 410/470 [01:04<00:09,  6.32it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  87% 411/470 [01:04<00:09,  6.32it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  88% 412/470 [01:05<00:09,  6.33it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  88% 413/470 [01:05<00:08,  6.34it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  88% 414/470 [01:05<00:08,  6.35it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  88% 415/470 [01:05<00:08,  6.36it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  89% 416/470 [01:05<00:08,  6.37it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  89% 417/470 [01:05<00:08,  6.38it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  89% 418/470 [01:05<00:08,  6.39it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  89% 419/470 [01:05<00:07,  6.39it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  89% 420/470 [01:05<00:07,  6.40it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  90% 421/470 [01:05<00:07,  6.41it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  90% 422/470 [01:05<00:07,  6.42it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  90% 423/470 [01:05<00:07,  6.43it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  90% 424/470 [01:05<00:07,  6.43it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  90% 425/470 [01:05<00:06,  6.44it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  91% 426/470 [01:06<00:06,  6.45it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  91% 427/470 [01:06<00:06,  6.46it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  91% 428/470 [01:06<00:06,  6.46it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  91% 429/470 [01:06<00:06,  6.48it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  91% 430/470 [01:06<00:06,  6.48it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  92% 431/470 [01:06<00:06,  6.49it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  92% 432/470 [01:06<00:05,  6.49it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  92% 433/470 [01:06<00:05,  6.50it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  92% 434/470 [01:06<00:05,  6.51it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  93% 435/470 [01:06<00:05,  6.52it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  93% 436/470 [01:06<00:05,  6.52it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  93% 437/470 [01:06<00:05,  6.53it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  93% 438/470 [01:06<00:04,  6.54it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  93% 439/470 [01:07<00:04,  6.55it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  94% 440/470 [01:07<00:04,  6.55it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  94% 441/470 [01:07<00:04,  6.57it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  94% 442/470 [01:07<00:04,  6.57it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  94% 443/470 [01:07<00:04,  6.58it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  94% 444/470 [01:07<00:03,  6.59it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  95% 445/470 [01:07<00:03,  6.60it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  95% 446/470 [01:07<00:03,  6.60it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  95% 447/470 [01:07<00:03,  6.61it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  95% 448/470 [01:07<00:03,  6.62it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  96% 449/470 [01:07<00:03,  6.63it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  96% 450/470 [01:07<00:03,  6.63it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  96% 451/470 [01:07<00:02,  6.64it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  96% 452/470 [01:07<00:02,  6.65it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  96% 453/470 [01:08<00:02,  6.66it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  97% 454/470 [01:08<00:02,  6.66it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  97% 455/470 [01:08<00:02,  6.67it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  97% 456/470 [01:08<00:02,  6.67it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  97% 457/470 [01:08<00:01,  6.68it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  97% 458/470 [01:08<00:01,  6.69it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  98% 459/470 [01:08<00:01,  6.70it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  98% 460/470 [01:08<00:01,  6.70it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  98% 461/470 [01:08<00:01,  6.71it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  98% 462/470 [01:08<00:01,  6.72it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  99% 463/470 [01:08<00:01,  6.73it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  99% 464/470 [01:08<00:00,  6.73it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  99% 465/470 [01:08<00:00,  6.74it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  99% 466/470 [01:09<00:00,  6.74it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16:  99% 467/470 [01:09<00:00,  6.75it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16: 100% 468/470 [01:09<00:00,  6.76it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16: 100% 469/470 [01:09<00:00,  6.77it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.868]\n",
            "Epoch 16: 100% 470/470 [01:09<00:00,  6.79it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.867]\n",
            "Epoch 16: 100% 470/470 [01:09<00:00,  6.78it/s, loss=0.0513, v_num=3, train_accuracy=0.984, val_accuracy=0.867]Epoch 00017: reducing learning rate of group 0 to 2.5000e-05.\n",
            "Epoch 17:  83% 391/470 [01:00<00:12,  6.47it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 17:  83% 392/470 [01:00<00:12,  6.45it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  84% 393/470 [01:00<00:11,  6.47it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  84% 394/470 [01:00<00:11,  6.48it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  84% 395/470 [01:00<00:11,  6.49it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  84% 396/470 [01:00<00:11,  6.50it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  84% 397/470 [01:00<00:11,  6.52it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  85% 398/470 [01:01<00:11,  6.52it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  85% 399/470 [01:01<00:10,  6.53it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  85% 400/470 [01:01<00:10,  6.55it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  85% 401/470 [01:01<00:10,  6.56it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  86% 402/470 [01:01<00:10,  6.57it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  86% 403/470 [01:01<00:10,  6.59it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  86% 404/470 [01:01<00:10,  6.60it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  86% 405/470 [01:01<00:09,  6.61it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  86% 406/470 [01:01<00:09,  6.62it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  87% 407/470 [01:01<00:09,  6.63it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  87% 408/470 [01:01<00:09,  6.64it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  87% 409/470 [01:01<00:09,  6.66it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  87% 410/470 [01:01<00:08,  6.67it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  87% 411/470 [01:01<00:08,  6.68it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  88% 412/470 [01:01<00:08,  6.69it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  88% 413/470 [01:01<00:08,  6.70it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  88% 414/470 [01:01<00:08,  6.71it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  88% 415/470 [01:01<00:08,  6.72it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  89% 416/470 [01:01<00:08,  6.73it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  89% 417/470 [01:01<00:07,  6.74it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  89% 418/470 [01:01<00:07,  6.76it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  89% 419/470 [01:01<00:07,  6.77it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  89% 420/470 [01:01<00:07,  6.78it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  90% 421/470 [01:01<00:07,  6.79it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  90% 422/470 [01:02<00:07,  6.80it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  90% 423/470 [01:02<00:06,  6.81it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  90% 424/470 [01:02<00:06,  6.83it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  90% 425/470 [01:02<00:06,  6.84it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  91% 426/470 [01:02<00:06,  6.85it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  91% 427/470 [01:02<00:06,  6.86it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  91% 428/470 [01:02<00:06,  6.87it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  91% 429/470 [01:02<00:05,  6.88it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  91% 430/470 [01:02<00:05,  6.89it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  92% 431/470 [01:02<00:05,  6.91it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  92% 432/470 [01:02<00:05,  6.92it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  92% 433/470 [01:02<00:05,  6.92it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  92% 434/470 [01:02<00:05,  6.94it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  93% 435/470 [01:02<00:05,  6.95it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  93% 436/470 [01:02<00:04,  6.96it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  93% 437/470 [01:02<00:04,  6.97it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  93% 438/470 [01:02<00:04,  6.98it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  93% 439/470 [01:02<00:04,  6.99it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  94% 440/470 [01:02<00:04,  7.00it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  94% 441/470 [01:02<00:04,  7.01it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  94% 442/470 [01:02<00:03,  7.02it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  94% 443/470 [01:03<00:03,  7.03it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  94% 444/470 [01:03<00:03,  7.04it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  95% 445/470 [01:03<00:03,  7.05it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  95% 446/470 [01:03<00:03,  7.06it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  95% 447/470 [01:03<00:03,  7.07it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  95% 448/470 [01:03<00:03,  7.08it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  96% 449/470 [01:03<00:02,  7.09it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  96% 450/470 [01:03<00:02,  7.10it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  96% 451/470 [01:03<00:02,  7.11it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  96% 452/470 [01:03<00:02,  7.12it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  96% 453/470 [01:03<00:02,  7.13it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  97% 454/470 [01:03<00:02,  7.14it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  97% 455/470 [01:03<00:02,  7.15it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  97% 456/470 [01:03<00:01,  7.16it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  97% 457/470 [01:03<00:01,  7.17it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  97% 458/470 [01:03<00:01,  7.18it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  98% 459/470 [01:03<00:01,  7.19it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  98% 460/470 [01:03<00:01,  7.20it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  98% 461/470 [01:03<00:01,  7.21it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  98% 462/470 [01:03<00:01,  7.22it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  99% 463/470 [01:04<00:00,  7.23it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  99% 464/470 [01:04<00:00,  7.24it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  99% 465/470 [01:04<00:00,  7.25it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  99% 466/470 [01:04<00:00,  7.27it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17:  99% 467/470 [01:04<00:00,  7.28it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17: 100% 468/470 [01:04<00:00,  7.29it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17: 100% 469/470 [01:04<00:00,  7.30it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.867]\n",
            "Epoch 17: 100% 470/470 [01:04<00:00,  7.31it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.868]\n",
            "Epoch 17: 100% 470/470 [01:05<00:00,  7.20it/s, loss=0.0437, v_num=3, train_accuracy=0.987, val_accuracy=0.868]\n",
            "\u001b[0m"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}