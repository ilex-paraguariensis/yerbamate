{
    "package": "vit_pytorch",
    "backbone": "torch",
    "source": "pip-package-source",
    "url": "https://github.com/lucidrains/vit-pytorch",
    "dependencies": [
        "torch>=1.2.1",
        "torchvision"
    ],
    "type": "torch_models",
    "export": {
        "type": "model",
        "module": "vit_pytorch",
        "models": [
            {
                "name": "ViT",
                "submodule": "vit",
                "class": "ViT",
                "type": {
                    "module": "torch.nn",
                    "class": "Module"
                },
                "sample_params": {
                    "image_size": 256,
                    "patch_size": 16,
                    "num_classes": 1000,
                    "dim": 1024,
                    "depth": 6,
                    "heads": 16,
                    "pool": "cls",
                    "mlp_dim": 2048,
                    "dim_head": 64,
                    "dropout": 0.1,
                    "emb_dropout": 0.1
                },
                "required_params": [
                    "image_size",
                    "patch_size",
                    "num_classes"
                ],
                "requirements": {
                    "image_size": {
                        "type": "int",
                        "min": 16,
                        "meta_data": {
                            "description": "Image size",
                            "restrictions": "Image size should be divisible by patch size"
                        }
                    }
                },
                "metadata": {
                    "description": "ViT model",
                    "references": [
                        {
                            "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale",
                            "author": "Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby",
                            "year": 2020,
                            "link": "https://arxiv.org/abs/2010.11929"
                        }
                    ],
                    "category": "classifier",
                    "input_shape": [
                        "batch_size",
                        "channels",
                        "image_size",
                        "image_size"
                    ],
                    "output_shape": [
                        "batch_size",
                        "num_classes"
                    ]
                }
            },
            {
                "name": "Dino",
                "submodule": "dino",
                "class": "Dino",
                "type": {
                    "module": "torch.nn",
                    "class": "Module"
                },
                "sample_params": {
                    "net": {
                        "module": "vit_pytorch.vit",
                        "class": "ViT",
                        "params": {
                            "image_size": 256,
                            "patch_size": 16,
                            "num_classes": 1000
                        }
                    },
                    "image_size": 256
                },
                "required_params": [
                    "net",
                    "image_size"
                ],
                "requirements": {
                    "net": {
                        "type": {
                            "module": "torch.nn",
                            "class": "Module"
                        },
                        "source": {
                            "module": "vit_pytorch",
                            "submodule": "any",
                            "class_list": [
                                "ViT",
                                "LeViT"
                            ]
                        },
                        "meta_data": {
                            "description": "Network",
                            "restrictions": "Network must be a vision transformer"
                        }
                    },
                    "image_size": {
                        "type": "int",
                        "min": 16,
                        "meta_data": {
                            "description": "Image size",
                            "restrictions": "Image size should be divisible by patch size"
                        }
                    }
                }
            },
            "CrossViT",
            "DeepViT",
            "CaiT",
            "T2TViT"
        ],
        "full_param_export_fle": "vit_full_params.json"
    },
    "description": "Vision Transformer (ViT) in PyTorch",
    "version": "0.22.0",
    "author": "lucidrains",
    "license": "MIT"
}